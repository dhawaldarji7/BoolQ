{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REEL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfBfWLXF4qz3"
      },
      "source": [
        "# Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Am7C1tfcryk"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install spacy-entity-Linker\n",
        "!python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download en_core_web_lg\n",
        "!python -m spacyEntityLinker \"download_knowledge_base\"\n",
        "\n",
        "!git clone https://github.com/thunlp/OpenNRE.git\n",
        "\n",
        "%cd OpenNRE/\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install \n",
        "\n",
        "# NOTE: Restart the runtime after running this cell."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrW41DNp4126"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpIgxE9-4xdI"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from spacyEntityLinker.EntityLinker import EntityLinker\n",
        "import os\n",
        "import opennre as on"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veL4krle44QD"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7ehE5f9gMPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c6521f-3cc2-4046-f83f-6ff62fa08839"
      },
      "source": [
        "# Load the data\n",
        "trainData = pd.read_json(\"./train.jsonl\", lines=True, orient=\"records\")\n",
        "valData = pd.read_json(\"./val.jsonl\", lines=True, orient=\"records\")\n",
        "testData = pd.read_json(\"./test.jsonl\", lines=True, orient=\"records\")\n",
        "\n",
        "# Train \n",
        "trainPassages = trainData.passage.values\n",
        "trainQuestions = trainData.question.values\n",
        "trainAnswers = trainData.label.values.astype(int)\n",
        "\n",
        "# Validation\n",
        "valPassages = valData.passage.values\n",
        "valQuestions = valData.question.values\n",
        "valAnswers = valData.label.values.astype(int)\n",
        "\n",
        "# Test\n",
        "testPassages = testData.passage.values\n",
        "testQuestions = testData.question.values\n",
        "\n",
        "\n",
        "# FinalSet\n",
        "finalPassages = np.concatenate((trainPassages, valPassages))\n",
        "finalPassages = np.concatenate((finalPassages, testPassages))\n",
        "\n",
        "finalQuestions = np.concatenate((trainQuestions, valQuestions))\n",
        "finalQuestions = np.concatenate((finalQuestions, testQuestions))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-09 19:57:28,452 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTPfmsn7c0Xa"
      },
      "source": [
        "#Initialize Entity Linker\n",
        "entityLinker = EntityLinker()\n",
        "\n",
        "#initialize language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#add pipeline\n",
        "nlp.add_pipe(entityLinker, last=True, name=\"entityLinker\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_Jyss048bH"
      },
      "source": [
        "# Entity Linking & Relation Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJlz-bHdcXmk",
        "outputId": "84077045-48f0-4df3-ae92-95de8cf2cb12"
      },
      "source": [
        "model = on.get_model('wiki80_bert_softmax')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-09 19:58:49,051 - root - INFO - Loading BERT pre-trained checkpoint.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REEirBoIeGu_",
        "outputId": "e00eef02-5140-4751-e22e-066e1ae16d57"
      },
      "source": [
        "model1 = on.get_model('wiki80_bertentity_softmax')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-09 20:02:09,686 - root - INFO - Loading BERT pre-trained checkpoint.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd2moqnOGVJx"
      },
      "source": [
        "def augmentData(questions, passages, labels, file=''):\n",
        "\n",
        "  augData = open(\"Augmented_\" + file + \".jsonl\", 'w')\n",
        "\n",
        "  for question, passage, label in zip(questions, passages, labels):\n",
        "    \n",
        "    qpDict = {}\n",
        "\n",
        "    qpDict['question'] = question\n",
        "\n",
        "    # This gives all the entities present in the question and passage\n",
        "    q = nlp(question)\n",
        "    p = nlp(passage)\n",
        "\n",
        "    #returns all linked entities in the question and passage\n",
        "    qEnts = q._.linkedEntities\n",
        "    pEnts = p._.linkedEntities\n",
        "\n",
        "    if len(qEnts):\n",
        "\n",
        "      for qe in qEnts:\n",
        "        \n",
        "        if qe.get_label() != None:\n",
        "          if qe.get_label() in passage:\n",
        "            qeDes = qe.get_description()\n",
        "          \n",
        "            if qeDes not in passage:\n",
        "              passage = passage + qeDes\n",
        "\n",
        "      qpDict['passage'] = passage\n",
        "      qpDict['label'] = int(label)\n",
        "\n",
        "      augData.write(json.dumps(qpDict) + '\\n')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdCvfmlNuSaY"
      },
      "source": [
        "augmentData(trainQuestions, trainPassages, trainAnswers, 'train')\n",
        "augmentData(valQuestions, valPassages, valAnswers, 'val')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxIEj2ZU1rJY"
      },
      "source": [
        "\n",
        "    # print(question)\n",
        "    # print(passage)\n",
        "\n",
        "    # sents = passage.split('.')\n",
        "    # # print(sents)\n",
        "\n",
        "    # # check whether the question has any entities\n",
        "    # if len(qEnts) > 0:\n",
        "\n",
        "    #   # for every entity in question\n",
        "    #   for qe in qEnts:\n",
        "      \n",
        "    #     qe = qe.get_label()\n",
        "    #     qeLen = len(qe)\n",
        "\n",
        "    #     # perform relation extraction of entities present in both question and passage\n",
        "    #     # A entity which is present in both question and passage is used to find relations with all other entities of the passage\n",
        "    #     if qe in passage:\n",
        "\n",
        "    #       # perform sentential relation extraction using every sentence of the passage\n",
        "    #       # for sent in sents:\n",
        "\n",
        "\n",
        "    #       for pe in pEnts:\n",
        "    #         pe = pe.get_label()\n",
        "    #         # if pe in sent and qe in sent and pe != qe:\n",
        "              \n",
        "    #         qeStart = passage.index(qe)\n",
        "    #         qeEnd = qeStart + qeLen - 1\n",
        "\n",
        "    #         peLen = len(pe)\n",
        "    #         if pe in passage and pe != qe:\n",
        "    #           peStart = passage.index(pe)\n",
        "    #           peEnd = peStart + peLen - 1\n",
        "\n",
        "    #           hPos = {'pos': (qeStart, qeEnd)}\n",
        "    #           tPos = {'pos': (peStart, peEnd)}\n",
        "\n",
        "              \n",
        "    #           pred, conf = (model1.infer({'text': passage, 'h': hPos, 't': tPos}))\n",
        "\n",
        "    #           if conf > 0.85:\n",
        "    #             print(\"Qe: %s, Pe: %s\" % (qe,pe))\n",
        "    #             print(pred,conf)\n",
        "    #   break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}