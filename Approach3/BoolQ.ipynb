{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BoolQ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJhStTYJlFc9"
      },
      "source": [
        "# Libraries and Dependencies"
      ],
      "id": "CJhStTYJlFc9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "intense-butler"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "\n",
        "# install the sentencepiece library\n",
        "# NOTE: if installing for the first time and if using google colab, restart the runtime after installation\n",
        "!pip install sentencepiece"
      ],
      "id": "intense-butler",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3aAqlQIlMzN"
      },
      "source": [
        "# Imports"
      ],
      "id": "T3aAqlQIlMzN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "silver-adobe"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import datetime as dt\n",
        "import random\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import RandomSampler, SequentialSampler, TensorDataset, DataLoader\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, BertForSequenceClassification, BertTokenizer,AdamW\n",
        "from transformers import DebertaForSequenceClassification, AlbertForSequenceClassification, ElectraForSequenceClassification\n",
        "from transformers import DebertaTokenizer, AlbertTokenizer, ElectraTokenizer\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "id": "silver-adobe",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnNIIO_MldpW"
      },
      "source": [
        "# Pre-trained Models"
      ],
      "id": "OnNIIO_MldpW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hollywood-tongue"
      },
      "source": [
        "# Use GPU if available else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", device)\n",
        "\n",
        "# import the pre-trained models\n",
        "modelB = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "modelR = RobertaForSequenceClassification.from_pretrained(\"roberta-base\").to(device)\n",
        "modelE = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\").to(device)\n",
        "modelA = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\").to(device)\n",
        "modelD = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\").to(device)\n",
        "\n",
        "# Tokenizers to be used\n",
        "tokenizerB = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizerR = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "tokenizerE = ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
        "tokenizerA = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "tokenizerD = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "print(\"Model ready to be fine-tuned!!!\")"
      ],
      "id": "hollywood-tongue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpz5c3awli1P"
      },
      "source": [
        "# Data Loading"
      ],
      "id": "Mpz5c3awli1P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gothic-princeton"
      },
      "source": [
        "def loadAugmentedData():\n",
        "\n",
        "  trainData = pd.read_json(\"./Augmented_train.jsonl\", lines=True, orient=\"records\")\n",
        "  valData = pd.read_json(\"./Augmented_val.jsonl\", lines=True, orient=\"records\")\n",
        "  \n",
        "  # Train \n",
        "  trainPassages = trainData.passage.values\n",
        "  trainQuestions = trainData.question.values\n",
        "  trainAnswers = trainData.label.values\n",
        "\n",
        "  # Validation\n",
        "  valPassages = valData.passage.values\n",
        "  valQuestions = valData.question.values\n",
        "  valAnswers = valData.label.values\n",
        "\n",
        "  return trainQuestions, trainPassages, trainAnswers, valQuestions, valPassages, valAnswers\n",
        "\n",
        "trainQuestions, trainPassages, trainAnswers, valQuestions, valPassages, valAnswers = loadAugmentedData()"
      ],
      "id": "gothic-princeton",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL_P_tWulmXH"
      },
      "source": [
        "# Tokenization"
      ],
      "id": "vL_P_tWulmXH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lAVCay_I0eN"
      },
      "source": [
        "def tokenizeData(tokenizer, questions, passages, max_length=256):\n",
        "    \"\"\"Encode the question/passage pairs into features than can be fed to the model.\"\"\"\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for question, passage in zip(questions, passages):\n",
        "      tokenizedData = tokenizer.encode_plus(question, passage, max_length=max_length, padding='max_length', truncation=\"longest_first\")\n",
        "      tokenizedQP = tokenizedData[\"input_ids\"]\n",
        "      attentionMask = tokenizedData[\"attention_mask\"]\n",
        "\n",
        "      input_ids.append(tokenizedQP)\n",
        "      attention_masks.append(attentionMask)\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)\n"
      ],
      "id": "2lAVCay_I0eN",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-yAgp6hlpUi"
      },
      "source": [
        "# Building Dataloaders"
      ],
      "id": "Q-yAgp6hlpUi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "variable-sport"
      },
      "source": [
        "# Building the Dataloaders\n",
        "\n",
        "def buildDataLoaders(batchSize, trainFeatures, valFeatures):\n",
        "  trainTensors = [torch.tensor(feature, dtype=torch.long) for feature in trainFeatures]\n",
        "  valTensors = [torch.tensor(feature, dtype=torch.long) for feature in valFeatures]\n",
        "\n",
        "  trainDataset = TensorDataset(*trainTensors)\n",
        "  valDataset = TensorDataset(*valTensors)\n",
        "\n",
        "  trainSampler = RandomSampler(trainDataset)\n",
        "  valSampler = SequentialSampler(valDataset)\n",
        "\n",
        "  trainDataloader = DataLoader(trainDataset, sampler=trainSampler, batch_size=batchSize)\n",
        "  valDataloader = DataLoader(valDataset, sampler=valSampler, batch_size=batchSize)\n",
        "\n",
        "  return trainDataloader, valDataloader"
      ],
      "id": "variable-sport",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJoAFVuhltDY"
      },
      "source": [
        "# Fine-Tuning"
      ],
      "id": "uJoAFVuhltDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "united-mississippi"
      },
      "source": [
        "# Fine-tune the model on downstream task: BoolQ\n",
        "def train(numEpochs, gradSteps, model, optimizer, trainDataLoader, type=\"regular\"):\n",
        "    \n",
        "  trainLossHistory = []\n",
        "\n",
        "  for _ in tqdm(range(numEpochs), desc=\"Training Epoch's\"):\n",
        "\n",
        "    # Train the model for fine-tuning\n",
        "    epochTrainLoss = 0 # Cumulative loss\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    for step, batch in enumerate(trainDataLoader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        labels = batch[2].to(device)     \n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss = loss / gradSteps\n",
        "        epochTrainLoss += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        if (step + 1) % gradSteps == 0: # Gradient accumulation is over\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clipping gradients\n",
        "          optimizer.step()\n",
        "          model.zero_grad()\n",
        "\n",
        "    epochTrainLoss = epochTrainLoss / len(trainDataLoader)          \n",
        "    trainLossHistory.append(epochTrainLoss)\n",
        "\n",
        "  if not os.path.exists(\"./models/\"):\n",
        "    os.mkdir(\"./models/\")\n",
        "  \n",
        "  if not os.path.exists(\"./models/\" + type + \"/\"):\n",
        "    os.mkdir(\"./models/\" + type + \"/\")\n",
        "    \n",
        "  if model == modelB:\n",
        "    torch.save(model, \"./models/\" + type + \"/bert.pt\")\n",
        "\n",
        "  sns.set()\n",
        "  plt.plot(trainLossHistory, label=\"Train_Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Training Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks(np.arange(0, 3))\n",
        "  plt.show()"
      ],
      "id": "united-mississippi",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v69quqIWiUFV"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "v69quqIWiUFV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Ya4lrVMz8e"
      },
      "source": [
        "# Evaluation on validation set\n",
        "def eval(valDataLoader, numEpochs, model):\n",
        "    valAccuracy = []\n",
        "    valF1 = []\n",
        "\n",
        "    for _ in tqdm(range(numEpochs), desc=\"Validation Epoch's\"):\n",
        "      epochValAcc = 0\n",
        "      epochValF1 = 0\n",
        "      model.eval()\n",
        "      for batch in valDataLoader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        labels = batch[2]\n",
        "                    \n",
        "        with torch.no_grad():        \n",
        "            outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                        \n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        \n",
        "        predictions = np.argmax(logits, axis=1).flatten()\n",
        "        labels = labels.numpy().flatten()\n",
        "        epochValF1 += f1_score(predictions, labels)\n",
        "        epochValAcc += np.sum(predictions == labels) / len(labels)\n",
        "\n",
        "      epochValAcc = epochValAcc / len(valDataLoader)\n",
        "      epochValF1 = epochValF1 / len(valDataLoader)\n",
        "      valAccuracy.append(epochValAcc)\n",
        "      valF1.append(epochValF1)\n",
        "\n",
        "    acc = sum(valAccuracy) / len(valAccuracy)\n",
        "    f1 = sum(valF1) / len(valF1)\n",
        "    print(\"\\nVal Accuracy:\", acc)\n",
        "    print(\"Val F1:\", f1)\n",
        "\n",
        "    \n",
        "    plt.plot(valAccuracy, label=\"Val_Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Evaluation Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, 3))\n",
        "    plt.show()\n",
        "\n",
        "    return acc, f1"
      ],
      "id": "e4Ya4lrVMz8e",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HppGYFt8lw0i"
      },
      "source": [
        "# Predictions"
      ],
      "id": "HppGYFt8lw0i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVT2HUyG-mYg"
      },
      "source": [
        "# Making Predictions on the test set\n",
        "def predict(question, passage, max_length=512):\n",
        "  sequence = tokenizer.encode_plus(question, passage, max_length=max_length,\n",
        "                                   padding='max_length', truncation=\"longest_first\" \n",
        "                                   , return_tensors=\"pt\")['input_ids'].to(device)\n",
        "  \n",
        "  logits = model(sequence)[0]\n",
        "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
        "  proba_yes = round(probabilities[1], 2)\n",
        "  proba_no = round(probabilities[0], 2)\n",
        "  return (f\"Question: {question}, Yes: {proba_yes}, No: {proba_no}\")\n",
        "\n",
        "# for i in range(len(testPassages)):\n",
        "#   testPred.write(f\"\\n{i}\" + \": \" + predict(testQuestions[i], testPassages[i]))\n",
        "  \n",
        "\n"
      ],
      "id": "yVT2HUyG-mYg",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcmDenAbmAe2"
      },
      "source": [
        "def runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, type=\"Regular\"):\n",
        "\n",
        "  print(\"Fine-tuning and evaluating the model...\")\n",
        "  # Tokenize the data\n",
        "  trainIds, trainAttMasks = tokenizeData(tokenizer, trainQuestions, trainPassages, maxSeqLength)\n",
        "  valIds, valAttMasks = tokenizeData(tokenizer, valQuestions, valPassages, maxSeqLength)\n",
        "  # testIds, testAttMasks = tokenizeData(tokenizer, testQuestions, testPassages, maxSeqLength)\n",
        "\n",
        "  trainFeatures = (trainIds, trainAttMasks , trainAnswers)\n",
        "  valFeatures = (valIds, valAttMasks, valAnswers)\n",
        "  # testFeatures = (testIds, testAttMasks)\n",
        "\n",
        "  # Build the Dataloaders\n",
        "  trainDataLoader, valDataLoader = buildDataLoaders(batchSize, trainFeatures, valFeatures)\n",
        "\n",
        "  # Fine-tune\n",
        "  train(numEpochs, gradSteps, model, optimizer, trainDataLoader, type)\n",
        "\n",
        "  # Evaluate\n",
        "  acc, f1 = eval(valDataLoader, numEpochs, model)\n",
        "\n",
        "  # Writing results to a file\n",
        "  if model == modelB:\n",
        "    results = \"resultsBERT.txt\"\n",
        "  elif model == modelR:\n",
        "    results = \"resultRoBERTa.txt\" \n",
        "  elif model == modelE:\n",
        "    results = \"resultELECTRA.txt\"\n",
        "  elif model == modelA:\n",
        "    results = \"resultALBERT.txt\"\n",
        "  elif model == modelD:\n",
        "    results = \"resultDeBERTa.txt\"\n",
        "  \n",
        "  resultFile = open(results, \"w\")\n",
        "  resultFile.write(f\"Validation Accuracy: {round(acc, 2)}, Validation F1: {round(f1,2)}\")\n",
        "\n"
      ],
      "id": "YcmDenAbmAe2",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5EgahqtV0vy"
      },
      "source": [
        "def loadModel(model, tokenizer, batchSize, numEpochs):\n",
        "\n",
        "  print(\"Loading saved models for evaluation...\")\n",
        "  # Tokenize the data\n",
        "  trainIds, trainAttMasks = tokenizeData(tokenizer, trainQuestions, trainPassages, maxSeqLength)\n",
        "  valIds, valAttMasks = tokenizeData(tokenizer, valQuestions, valPassages, maxSeqLength)\n",
        "  # testIds, testAttMasks = tokenizeData(tokenizer, testQuestions, testPassages, maxSeqLength)\n",
        "\n",
        "  trainFeatures = (trainIds, trainAttMasks , trainAnswers)\n",
        "  valFeatures = (valIds, valAttMasks, valAnswers)\n",
        "  # testFeatures = (testIds, testAttMasks)\n",
        "\n",
        "  # Build the Dataloaders\n",
        "  trainDataLoader, valDataLoader = buildDataLoaders(batchSize, trainFeatures, valFeatures)\n",
        "\n",
        "  # Evaluate\n",
        "  acc, f1 = eval(valDataLoader, numEpochs, model)\n",
        "\n",
        "  # Writing results to a file\n",
        "  if model == modelB:\n",
        "    results = \"resultsBERT.txt\"\n",
        "  elif model == modelR:\n",
        "    results = \"resultRoBERTa.txt\" \n",
        "  elif model == modelE:\n",
        "    results = \"resultELECTRA.txt\"\n",
        "  elif model == modelA:\n",
        "    results = \"resultALBERT.txt\"\n",
        "  elif model == modelD:\n",
        "    results = \"resultDeBERTa.txt\"\n",
        "  \n",
        "  resultFile = open(results, \"w\")\n",
        "  resultFile.write(f\"Validation Accuracy: {round(acc, 2)}, Validation F1: {round(f1,2)}\")\n",
        "\n"
      ],
      "id": "N5EgahqtV0vy",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed5JHHXnW2-j"
      },
      "source": [
        "def runBERT(model, tokenizer, optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  print(\"\\nRunning BERT model\")\n",
        "  optimizer = AdamW(model.parameters(), lr=learningRate)\n",
        "  runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "def runROBERTA(model, tokenizer, optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  print(\"\\nRunning RoBERTa model\")\n",
        "  optimizer = AdamW(model.parameters(), lr=learningRate)\n",
        "  runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "def runELECTRA(model, tokenizer, optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  print(\"\\nRunning ELECTRA model\")\n",
        "  optimizer = AdamW(model.parameters(), lr=learningRate)\n",
        "  runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "def runALBERT(model, tokenizer, optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  print(\"\\nRunning ALBERT model\")\n",
        "  optimizer = AdamW(model.parameters(), lr=learningRate)\n",
        "  runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "def runDEBERTA(model, tokenizer, optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  print(\"\\nRunning DeBERTa model\")\n",
        "  optimizer = AdamW(model.parameters(), lr=learningRate)\n",
        "  runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "def runALL(optimizer, batchSize, learningRate, maxSeqLength, gradSteps, numEpochs, runType):\n",
        "  \n",
        "  print(\"\\nYou have selected to run all models\")\n",
        "\n",
        "  runBERT(modelB, tokenizerB, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "  runROBERTA(modelR, tokenizerR, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "  runELECTRA(modelE, tokenizerE, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "  runALBERT(modelA, tokenizerA, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "  runDEBERTA(modelD, tokenizerD, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "  "
      ],
      "id": "ed5JHHXnW2-j",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFY_YKzcOS7"
      },
      "source": [
        "def loadBERT(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"\\nLoading and evaluating BERT model\")\n",
        "  model = torch.load(\"./models/\" + runType + \"/bert.pt\")\n",
        "  loadModel(model, tokenizerB, batchSize, learningRate, numEpochs)\n",
        "\n",
        "def loadROBERTA(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"\\nLoading and evaluating RoBERTa model\")\n",
        "  model = torch.load(\"./models/\" + runType + \"/roberta.pt\")\n",
        "  loadModel(model, tokenizerR, batchSize, learningRate, numEpochs)\n",
        "\n",
        "def loadELECTRA(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"\\nLoading and evaluating ELECTRA model\")\n",
        "  model = torch.load(\"./models/\" + runType + \"/electra.pt\")\n",
        "  loadModel(model, tokenizerE, batchSize, learningRate, numEpochs)\n",
        "\n",
        "def loadALBERT(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"\\nLoading and evaluating ALBERT model\")\n",
        "  model = torch.load(\"./models/\" + runType + \"/albert.pt\")\n",
        "  loadModel(model, tokenizerA, batchSize, learningRate, numEpochs)\n",
        "\n",
        "def loadDEBERTA(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"\\nLoading and evaluating DeBERTa model\")\n",
        "  model = torch.load(\"./models/\" + runType + \"/deberta.pt\")\n",
        "  loadModel(model, tokenizerD, batchSize, learningRate, numEpochs)\n",
        "\n",
        "def loadALL(batchSize, learningRate, numEpochs, runType):\n",
        "  print(\"You have selected to load all the models and evaluate them.\")\n",
        "  loadBERT(batchSize, learningRate, numEpochs, runType)\n",
        "  loadROBERTA(batchSize, learningRate, numEpochs, runType)\n",
        "  loadELECTRA(batchSize, learningRate, numEpochs, runType)\n",
        "  loadALBERT(batchSize, learningRate, numEpochs, runType)\n",
        "  loadDEBERTA(batchSize, learningRate, numEpochs, runType)\n",
        "\n"
      ],
      "id": "yFFY_YKzcOS7",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYCakbh5lz9M"
      },
      "source": [
        "# Testing"
      ],
      "id": "RYCakbh5lz9M"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I50RP5kuidSo"
      },
      "source": [
        "print(\"Models Available:\\n 1: BERT \\n 2: RoBERTa \\n 3: ELECTRA \\n 4: ALBERT \\n 5: DeBERTa \\n 6: All\\n\")\n",
        "choice = int(input(\"Select the model you'd like to run:\"))\n",
        "choice2 = int(input(\"What would you like to do: \\n1: Fine-Tune and Evaluate \\n2: Load and Evaluate\"))\n",
        "\n",
        "learningRate = float(input(\"Please enter a learning rate:(e.g. 1e-5)\"))\n",
        "batchSize = int(input(\"Please enter batch size:(e.g. 8)\"))\n",
        "numEpochs = int(input(\"Please enter the number of epochs:(e.g. 3)\"))\n",
        "maxSeqLength = int(input(\"Please enter the maximum sequence length:(e.g. 128)\"))\n",
        "gradSteps = int(input(\"Please enter the number of gradient steps:(e.g. 3)\"))\n",
        "runType = input(\"Please input the run type: (e.g. augDhawal)\")\n",
        "\n",
        "if choice2 == 1:\n",
        "\n",
        "  if choice == 1:\n",
        "    runBERT(modelB, tokenizerB, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "  elif choice == 2:\n",
        "    runROBERTA(modelR, tokenizerR, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "  elif choice == 3:\n",
        "    runELECTRA(modelE, tokenizerE, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "  elif choice == 4:\n",
        "    runALBERT(modelA, tokenizerA, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "  elif choice == 5:\n",
        "    runDEBERTA(modelD, tokenizerD, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "  elif choice == 6:\n",
        "    runAll(optimizer, batchSize, maxSeqLength, gradSteps, numEpochs, runType)\n",
        "\n",
        "elif choice2 == 2:\n",
        "\n",
        "  if choice == 1:\n",
        "    loadBERT(batchSize, learningRate, numEpochs, runType)\n",
        "\n",
        "  elif choice == 2:\n",
        "    loadROBERTA(batchSize, learningRate, numEpochs, runType)\n",
        "\n",
        "  elif choice == 3:\n",
        "    loadELECTRA(batchSize, learningRate, numEpochs, runType)\n",
        "\n",
        "  elif choice == 4:\n",
        "    loadALBERT(batchSize, learningRate, numEpochs, runType)\n",
        "\n",
        "  elif choice == 5:\n",
        "    loadDEBERTA(batchSize, learningRate, numEpochs, runType)\n",
        "\n",
        "  elif choice == 6:\n",
        "    loadAll(batchSize, learningRate, numEpochs, runType)"
      ],
      "id": "I50RP5kuidSo",
      "execution_count": null,
      "outputs": []
    }
  ]
}