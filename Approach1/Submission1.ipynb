{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Submission1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKYapuCk5oDhECxWmDim29",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhawaldarji7/BoolQ/blob/main/Submission1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cqHeMCRTKeP",
        "outputId": "02b241a5-8188-4db0-b53e-2776093f63c5"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install transformers==2.5.1\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "\n",
        "!gsutil cp gs://boolq/train.jsonl .\n",
        "!gsutil cp gs://boolq/dev.jsonl ."
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.1.95)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.17.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.3.4)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.24 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.20.24)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.24->boto3->transformers==2.5.1) (2.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Copying gs://boolq/train.jsonl...\n",
            "- [1 files][  6.2 MiB/  6.2 MiB]                                                \n",
            "Operation completed over 1 objects/6.2 MiB.                                      \n",
            "Copying gs://boolq/dev.jsonl...\n",
            "- [1 files][  2.1 MiB/  2.1 MiB]                                                \n",
            "Operation completed over 1 objects/2.1 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XKkv9BxTfQH"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wToxStMTToM8"
      },
      "source": [
        "# Loading data\n",
        "train_data_df = pd.read_json(\"/content/train.jsonl\", lines=True, orient='records')\n",
        "dev_data_df = pd.read_json(\"/content/dev.jsonl\", lines=True, orient=\"records\")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Fp0iEBnFHMIb",
        "outputId": "249ba1e2-c088-409e-857a-f5ca177044fb"
      },
      "source": [
        "dev_data_df"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "      <th>answer</th>\n",
              "      <th>passage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>does ethanol take more energy make that produces</td>\n",
              "      <td>Ethanol fuel</td>\n",
              "      <td>False</td>\n",
              "      <td>All biomass goes through at least some of thes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is house tax and property tax are same</td>\n",
              "      <td>Property tax</td>\n",
              "      <td>True</td>\n",
              "      <td>Property tax or 'house tax' is a local tax on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is pain experienced in a missing body part or ...</td>\n",
              "      <td>Phantom pain</td>\n",
              "      <td>True</td>\n",
              "      <td>Phantom pain sensations are described as perce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>is harry potter and the escape from gringotts ...</td>\n",
              "      <td>Harry Potter and the Escape from Gringotts</td>\n",
              "      <td>True</td>\n",
              "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
              "      <td>Hydroxyzine</td>\n",
              "      <td>True</td>\n",
              "      <td>Hydroxyzine preparations require a doctor's pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>is manic depression the same as bi polar</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>True</td>\n",
              "      <td>Bipolar disorder, previously known as manic de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>was whiskey galore based on a true story</td>\n",
              "      <td>SS Politician</td>\n",
              "      <td>True</td>\n",
              "      <td>SS Politician was an 8000-ton cargo ship owned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>are there plants on the international space st...</td>\n",
              "      <td>Plants in space</td>\n",
              "      <td>True</td>\n",
              "      <td>Plant research continued on the International ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>does the hockey puck have to cross the line to...</td>\n",
              "      <td>Goal (ice hockey)</td>\n",
              "      <td>True</td>\n",
              "      <td>In ice hockey, a goal is scored when the puck ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>will there be a season 5 of shadowhunters</td>\n",
              "      <td>List of Shadowhunters episodes</td>\n",
              "      <td>False</td>\n",
              "      <td>In April 2017, it was announced that the serie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3270 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  ...                                            passage\n",
              "0      does ethanol take more energy make that produces  ...  All biomass goes through at least some of thes...\n",
              "1                is house tax and property tax are same  ...  Property tax or 'house tax' is a local tax on ...\n",
              "2     is pain experienced in a missing body part or ...  ...  Phantom pain sensations are described as perce...\n",
              "3     is harry potter and the escape from gringotts ...  ...  Harry Potter and the Escape from Gringotts is ...\n",
              "4     is there a difference between hydroxyzine hcl ...  ...  Hydroxyzine preparations require a doctor's pr...\n",
              "...                                                 ...  ...                                                ...\n",
              "3265           is manic depression the same as bi polar  ...  Bipolar disorder, previously known as manic de...\n",
              "3266           was whiskey galore based on a true story  ...  SS Politician was an 8000-ton cargo ship owned...\n",
              "3267  are there plants on the international space st...  ...  Plant research continued on the International ...\n",
              "3268  does the hockey puck have to cross the line to...  ...  In ice hockey, a goal is scored when the puck ...\n",
              "3269          will there be a season 5 of shadowhunters  ...  In April 2017, it was announced that the serie...\n",
              "\n",
              "[3270 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZVVhnnhTs-y"
      },
      "source": [
        "passages_train = train_data_df.passage.values\n",
        "questions_train = train_data_df.question.values\n",
        "answers_train = train_data_df.answer.values.astype(int)\n",
        "passages_dev = dev_data_df.passage.values\n",
        "questions_dev = dev_data_df.question.values\n",
        "answers_dev = dev_data_df.answer.values.astype(int)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxB579FhTxHb",
        "outputId": "088308e2-7ac6-4208-94c4-587d4d47b4ed"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6mrtyOxUScK",
        "outputId": "70be422c-9415-4163-e3d8-e89302e27d42"
      },
      "source": [
        "print(passages_train)\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "   "
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.'\n",
            " \"Good Samaritan laws offer legal protection to people who give reasonable assistance to those who are, or who they believe to be, injured, ill, in peril, or otherwise incapacitated. The protection is intended to reduce bystanders' hesitation to assist, for fear of being sued or prosecuted for unintentional injury or wrongful death. An example of such a law in common-law areas of Canada: a good Samaritan doctrine is a legal principle that prevents a rescuer who has voluntarily helped a victim in distress from being successfully sued for wrongdoing. Its purpose is to keep people from being reluctant to help a stranger in need for fear of legal repercussions should they make some mistake in treatment. By contrast, a duty to rescue law requires people to offer assistance and holds those who fail to do so liable.\"\n",
            " 'Windows Movie Maker (formerly known as Windows Live Movie Maker in Windows 7) is a discontinued video editing software by Microsoft. It is a part of Windows Essentials software suite and offers the ability to create and edit videos as well as to publish them on OneDrive, Facebook, Vimeo, YouTube, and Flickr.'\n",
            " ...\n",
            " 'The Warriors went into the 2018 playoffs as the second seed in the Western Conference after earning a 2017--18 regular season record of 58--24 . After defeating both the Spurs and the Pelicans 4-1, the Warriors came up against the top-seeded Houston Rockets in the Western Conference Finals. Despite reaching a 3-2 disadvantage against the Rockets after Game 5, the Warriors were able to stave off elimination and came back to win the series 4-3. The 2018 Finals once again pitted the Warriors against the Cavaliers, becoming the first time in NBA history that two teams met in the Finals for four consecutive years. The Warriors won their second-straight NBA championship after going 4--0 in the Finals, marking the first NBA Finals sweep since 2007.'\n",
            " 'Downton Abbey is a British period drama television series created by Julian Fellowes and co-produced by Carnival Films and Masterpiece. It first aired on ITV in the United Kingdom on 26 September 2010, and on PBS in the United States on 9 January 2011, as part of the Masterpiece Classic anthology. Six series have been made, the sixth airing in the autumn of 2015 in the UK and Ireland, and in January 2016 in the United States. On 26 March 2015, the sixth series was confirmed to be the final series, with the final episode airing in the UK on 25 December 2015 on ITV. During the course of the programme, 52 episodes of Downton Abbey aired over six series.'\n",
            " \"The margin of error is usually defined as the ``radius'' (or half the width) of a confidence interval for a particular statistic from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported percentages using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%.\"]\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPiRwvzo0pP_"
      },
      "source": [
        "#for sent in questions_train:\n",
        "  #print(sent.split()[0])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aCtKOZoUEww",
        "outputId": "86f1eb07-6789-4b7d-dcf5-a3522be3b113"
      },
      "source": [
        "#selecting the important question words that is verb or noun or the starting question word\n",
        "#This is only for selecting the sentences from the passages.\n",
        "array = []\n",
        "for sent in questions_train[0:9427]:\n",
        "    rows = []\n",
        "    question_word =\"\"\n",
        "    question_word = sent.split()[0]\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokenize_word)\n",
        "    for word, tag in tagged:\n",
        "      if tag in ('NN', 'VB'):\n",
        "        rows.append(word)\n",
        "        rows.append(word.capitalize())\n",
        "        #or (word == sent.split()[0])\n",
        "        #rows.append(tuple((word,tag)))\n",
        "        #rows.append(tuple((word.capitalize(),tag)))\n",
        "    \n",
        "    array.append(rows)\n",
        "print(array[3])\n",
        "\n",
        "#This will be used for making features from the questions and passages.\n",
        "array_ques = []\n",
        "for sent in questions_train[0:9427]:\n",
        "    rows = []\n",
        "    question_word =\"\"\n",
        "    question_word = sent.split()[0]\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokenize_word)\n",
        "    for word, tag in tagged:\n",
        "      if tag in ('NN', 'VB') or (word == sent.split()[0]):\n",
        "        rows.append(word)\n",
        "        rows.append(word.capitalize())\n",
        "        #or (word == sent.split()[0])\n",
        "        #rows.append(tuple((word,tag)))\n",
        "        #rows.append(tuple((word.capitalize(),tag)))\n",
        "    \n",
        "    array_ques.append(rows)\n",
        "print(array_ques[3])"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sugar', 'Sugar', 'sugar', 'Sugar']\n",
            "['is', 'Is', 'sugar', 'Sugar', 'sugar', 'Sugar']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqAhfMlz_y2m",
        "outputId": "4483bb3e-1ba0-4e4c-9422-b43a288c0920"
      },
      "source": [
        "for word in array[1]:\n",
        "  print(word)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "do\n",
            "Do\n",
            "samaritan\n",
            "Samaritan\n",
            "accident\n",
            "Accident\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBFaSQBD8Per",
        "outputId": "44c131ef-b88d-41b9-fa97-46fe8beeea1c"
      },
      "source": [
        "#selection of passage lines with the given shortlisted words from question\n",
        "double_passage_line = []\n",
        "for i in range(0,9427):\n",
        "  passage_line = \"\"\n",
        "  sentences = sent_tokenize(passages_train[i])\n",
        "  for sent in sentences:\n",
        "    if any(word in sent for word in array[i]):\n",
        "      passage_line += sent\n",
        "  #print(passage_line)\n",
        "  double_passage_line.append(passage_line)\n",
        "\n",
        "print(len(double_passage_line))\n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8V99V9u7_JT",
        "outputId": "675a18b1-4519-4103-e11c-9ca38d5195b4"
      },
      "source": [
        "print(passages_train)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.'\n",
            " \"Good Samaritan laws offer legal protection to people who give reasonable assistance to those who are, or who they believe to be, injured, ill, in peril, or otherwise incapacitated. The protection is intended to reduce bystanders' hesitation to assist, for fear of being sued or prosecuted for unintentional injury or wrongful death. An example of such a law in common-law areas of Canada: a good Samaritan doctrine is a legal principle that prevents a rescuer who has voluntarily helped a victim in distress from being successfully sued for wrongdoing. Its purpose is to keep people from being reluctant to help a stranger in need for fear of legal repercussions should they make some mistake in treatment. By contrast, a duty to rescue law requires people to offer assistance and holds those who fail to do so liable.\"\n",
            " 'Windows Movie Maker (formerly known as Windows Live Movie Maker in Windows 7) is a discontinued video editing software by Microsoft. It is a part of Windows Essentials software suite and offers the ability to create and edit videos as well as to publish them on OneDrive, Facebook, Vimeo, YouTube, and Flickr.'\n",
            " ...\n",
            " 'The Warriors went into the 2018 playoffs as the second seed in the Western Conference after earning a 2017--18 regular season record of 58--24 . After defeating both the Spurs and the Pelicans 4-1, the Warriors came up against the top-seeded Houston Rockets in the Western Conference Finals. Despite reaching a 3-2 disadvantage against the Rockets after Game 5, the Warriors were able to stave off elimination and came back to win the series 4-3. The 2018 Finals once again pitted the Warriors against the Cavaliers, becoming the first time in NBA history that two teams met in the Finals for four consecutive years. The Warriors won their second-straight NBA championship after going 4--0 in the Finals, marking the first NBA Finals sweep since 2007.'\n",
            " 'Downton Abbey is a British period drama television series created by Julian Fellowes and co-produced by Carnival Films and Masterpiece. It first aired on ITV in the United Kingdom on 26 September 2010, and on PBS in the United States on 9 January 2011, as part of the Masterpiece Classic anthology. Six series have been made, the sixth airing in the autumn of 2015 in the UK and Ireland, and in January 2016 in the United States. On 26 March 2015, the sixth series was confirmed to be the final series, with the final episode airing in the UK on 25 December 2015 on ITV. During the course of the programme, 52 episodes of Downton Abbey aired over six series.'\n",
            " \"The margin of error is usually defined as the ``radius'' (or half the width) of a confidence interval for a particular statistic from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported percentages using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-kWUNc44dc8",
        "outputId": "55bdf08a-b07c-406a-83f4-73709dea1877"
      },
      "source": [
        "print(array[5])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['use', 'Use', 'card', 'Card', 'station', 'Station']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55a1zyef0SkJ"
      },
      "source": [
        "\n",
        "rows, cols = (9427, 2) \n",
        "\n",
        "arr=[]\n",
        "for i in range(rows):\n",
        "  row = []\n",
        "  for j in range(cols):\n",
        "    if j==0:\n",
        "      tokenize_word = word_tokenize(questions_train[i])\n",
        "      tagged = nltk.pos_tag(tokenize_word)\n",
        "      row.append(tagged)\n",
        "    else:\n",
        "      #tokenize_word = double_passage_line[i]\n",
        "      tokenize_word = word_tokenize(double_passage_line[i])\n",
        "      #tagged = nltk.pos_tag(tokenize_word)\n",
        "      row.append(tokenize_word)\n",
        "  arr.append(row)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYjmy6MMXpWH",
        "outputId": "f04ef77f-8fff-4f65-ff89-9575ae787045"
      },
      "source": [
        "!pip install -U bert-serving-server bert-serving-client"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-server\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hCollecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (22.0.3)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.19.5)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=fe51284cf6d9d421999f732abe39cbd9aa6589e1f7a0b91c40035991c59010f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, bert-serving-server, bert-serving-client\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-client-1.10.0 bert-serving-server-1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igo9wAEw77Zq"
      },
      "source": [
        "#function for checking the negative question verb \n",
        "def negation_check(first_word, sentence):\n",
        "  #print(first_word)\n",
        "  #print(sentence)\n",
        "  val = 0\n",
        "  \n",
        "  for word in sentence:\n",
        "    #print(word)\n",
        "    if first_word == \" will \" and (word == \"won't\" or word == \"Won't\") :\n",
        "      #print(\"1\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "    elif first_word == \" can \" and (word == \"can't\" or word == \"Can't\") :\n",
        "      #print(\"1\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "    \n",
        "    elif first_word == \" do \" and (word == \"don't\" or word == \"Don't\") :\n",
        "      #print(\"1\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "  \n",
        "    elif first_word == \" are \" and (word == \"aren't\" or word == \"Aren't\") :\n",
        "      #print(\"1\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "\n",
        "    elif first_word == \" does \" and (word == \"doesn't\" or word == \"Doesn't\"):\n",
        "      #print(\"2\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "\n",
        "    elif first_word == \" is \" and (word == \"isn't\" or word == \"Isn't\"):\n",
        "      #print(\"3\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "\n",
        "    elif first_word == \" was \" and (word == \"wasn't\" or word == \"Wasn't\"):\n",
        "      #print(\"5\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "\n",
        "    elif first_word == \" were \" and (word == \"weren't\" or word == \"Weren't\"):\n",
        "      #print(\"6\",\"present\")\n",
        "      val = 1\n",
        "      break\n",
        "\n",
        "    elif word == sentence[len(sentence)-1]:\n",
        "      #print(\"not present\")\n",
        "      val = 0\n",
        "      \n",
        "    else:\n",
        "      continue\n",
        "  return val\n",
        "    \n",
        "      "
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V22n5YXDHAF0"
      },
      "source": [
        "#function checking for not in the passage\n",
        "def not_check(sentence):\n",
        "  val = 0\n",
        "  for word in sentence:\n",
        "    \n",
        "    if word == \"not\":\n",
        "      val = 1\n",
        "      break\n",
        "  return val\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsUwtT7sMYNh"
      },
      "source": [
        "#function checking for verbs that are present in question are there in answer or not\n",
        "def check_for_verb(verb, sentence):\n",
        "  verb_present = 0\n",
        "  for word, tag in verb[1:]:\n",
        "    #print(word, tag)\n",
        "    if tag == 'VBZ' or tag == 'VB' or tag == 'VBP':\n",
        "      if word in sentence:\n",
        "        verb_present = 1\n",
        "        #print(\"verb is there\")\n",
        "        break\n",
        "  return verb_present\n",
        "  #print(sentence)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_nKgIfjU2Ei"
      },
      "source": [
        "#checking whether last noun in question is present in the passage or not?\n",
        "def check_for_last_noun(last_tuple, sentence):\n",
        "  #print(last_tuple[1])\n",
        "  #print(sentence)\n",
        "  last_noun_present = 0\n",
        "  if last_tuple[1] == 'NN' or last_tuple[1] == 'NNS' or last_tuple[1] == 'NNP':\n",
        "    if last_tuple[0] in sentence:\n",
        "      last_noun_present = 1\n",
        "  return last_noun_present\n",
        "  #print(sentence)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC_lI_4k_gN_"
      },
      "source": [
        "#function checking for similar verbs\n",
        "def check_similar_verb(verb_sent, sentence):\n",
        "  #print(\"verb_sent\", verb_sent)\n",
        "  #print(sentence)\n",
        "  val = 0\n",
        "  for word, tag in verb_sent:\n",
        "    if tag == 'VBP':\n",
        "      synonyms = [] \n",
        "      for syn_set in wordnet.synsets(word): \n",
        "        for l in syn_set.lemmas(): \n",
        "          synonyms.append(l.name()) \n",
        "      #print(word)\n",
        "      #print(synonyms)\n",
        "      #print()\n",
        "      if any(word in sentence for word in synonyms):\n",
        "        #print(\"present\")\n",
        "        val = 1\n",
        "  return val\n",
        "        \n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvksTSEzEBWz",
        "outputId": "04adbaf3-b8d0-4570-ce0e-7ad8cc92ecb9"
      },
      "source": [
        "print(arr[1])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('do', 'VB'), ('good', 'JJ'), ('samaritan', 'VB'), ('laws', 'NNS'), ('protect', 'VBP'), ('those', 'DT'), ('who', 'WP'), ('help', 'VBP'), ('at', 'IN'), ('an', 'DT'), ('accident', 'NN')], ['Good', 'Samaritan', 'laws', 'offer', 'legal', 'protection', 'to', 'people', 'who', 'give', 'reasonable', 'assistance', 'to', 'those', 'who', 'are', ',', 'or', 'who', 'they', 'believe', 'to', 'be', ',', 'injured', ',', 'ill', ',', 'in', 'peril', ',', 'or', 'otherwise', 'incapacitated.An', 'example', 'of', 'such', 'a', 'law', 'in', 'common-law', 'areas', 'of', 'Canada', ':', 'a', 'good', 'Samaritan', 'doctrine', 'is', 'a', 'legal', 'principle', 'that', 'prevents', 'a', 'rescuer', 'who', 'has', 'voluntarily', 'helped', 'a', 'victim', 'in', 'distress', 'from', 'being', 'successfully', 'sued', 'for', 'wrongdoing.By', 'contrast', ',', 'a', 'duty', 'to', 'rescue', 'law', 'requires', 'people', 'to', 'offer', 'assistance', 'and', 'holds', 'those', 'who', 'fail', 'to', 'do', 'so', 'liable', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXizpdea4aqz",
        "outputId": "bca37e27-f2f6-4d36-aae8-ab54a703b07f"
      },
      "source": [
        "#function for making the data using the given set of features\n",
        "def features(value, index):\n",
        "    \"\"\"Set of four features from lecture\"\"\"\n",
        "    #feature1 checking for the negation word\n",
        "    \n",
        "    #print(\"0th value\",value[1])\n",
        "    negation = 0\n",
        "    negation = negation_check(value[0][0][0], value[1])\n",
        "    #feature2 checking for not\n",
        "    not_word = 0\n",
        "    not_word = not_check(value[1])\n",
        "    #checking for VB present in ans or not.\n",
        "    verb_check = 0\n",
        "    verb_check = check_for_verb(value[0], value[1])\n",
        "    #checking for the last noun\n",
        "    last_noun = 0\n",
        "    ques_len = len(value[0])\n",
        "    last_noun = check_for_last_noun(value[0][ques_len-1], value[1])\n",
        "    \n",
        "    #check for similarity between the verbs present in question and answer\n",
        "    similar_verb = 0\n",
        "    if (verb_check==0):\n",
        "      similar_verb = check_similar_verb(value[0], value[1])\n",
        "    #checking for all the nouns present in the passage or not\n",
        "    all_nouns = 0\n",
        "    #all_nouns = \n",
        "    #bias\n",
        "    f1 = 1 if negation is 1 else 0\n",
        "    f2 = 1 if not_word is 1 else 0\n",
        "    f3 = 1 if verb_check is 1 else 0\n",
        "    f4 = 1 if last_noun is 1 else 0\n",
        "    f5 = 1 if similar_verb is 1 else 0\n",
        "    f6 = 1\n",
        "    return np.array([f1, f2, f3, f4, f5, f6])    \n",
        "\n",
        "feature_matrix = [[0,0,0,0,0,0]]\n",
        "for i in range(0,9427):\n",
        "    a = np.array(feature_matrix)\n",
        "    b = np.array([features(arr[i],i)])\n",
        "    #print(a)\n",
        "    #print(b)\n",
        "    feature_matrix = np.concatenate((a,b), axis=0)\n",
        "feature_matrix = feature_matrix[1:]\n",
        "print(len(feature_matrix))\n",
        "print(feature_matrix[9000:9020])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9427\n",
            "[[0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 1 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 1 1 1 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 1 1 0 0 1]\n",
            " [0 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfbiw18PTsR6",
        "outputId": "8fba3252-e256-45a5-d665-833fc9f2991c"
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9427, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTGCrXFFFq3Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "#import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz2S7F8fMch_",
        "outputId": "adb7ac5c-b0e7-4048-afea-658f06d6d027"
      },
      "source": [
        "#selecting the important question words that is verb or noun or the starting question word\n",
        "#This is only for selecting the sentences from the passages.\n",
        "array = []\n",
        "for sent in questions_dev[0:3270]:\n",
        "    rows = []\n",
        "    question_word =\"\"\n",
        "    question_word = sent.split()[0]\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokenize_word)\n",
        "    for word, tag in tagged:\n",
        "      if tag in ('NN', 'VB'):\n",
        "        rows.append(word)\n",
        "        rows.append(word.capitalize())\n",
        "        #or (word == sent.split()[0])\n",
        "        #rows.append(tuple((word,tag)))\n",
        "        #rows.append(tuple((word.capitalize(),tag)))\n",
        "    \n",
        "    array.append(rows)\n",
        "print(array[3])\n",
        "\n",
        "#This will be used for making features from the questions and passages.\n",
        "array_ques = []\n",
        "for sent in questions_dev[0:3270]:\n",
        "    rows = []\n",
        "    question_word =\"\"\n",
        "    question_word = sent.split()[0]\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokenize_word)\n",
        "    for word, tag in tagged:\n",
        "      if tag in ('NN', 'VB') or (word == sent.split()[0]):\n",
        "        rows.append(word)\n",
        "        rows.append(word.capitalize())\n",
        "        #or (word == sent.split()[0])\n",
        "        #rows.append(tuple((word,tag)))\n",
        "        #rows.append(tuple((word.capitalize(),tag)))\n",
        "    \n",
        "    array_ques.append(rows)\n",
        "print(array_ques[3])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['potter', 'Potter', 'escape', 'Escape', 'gringotts', 'Gringotts', 'roller', 'Roller', 'coaster', 'Coaster', 'ride', 'Ride']\n",
            "['is', 'Is', 'potter', 'Potter', 'escape', 'Escape', 'gringotts', 'Gringotts', 'roller', 'Roller', 'coaster', 'Coaster', 'ride', 'Ride']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNB0Q6SKNVHI",
        "outputId": "92d7cf11-243f-450c-b4d8-7e97cb60c7ec"
      },
      "source": [
        "#selection of passage lines with the given shortlisted words from question\n",
        "double_passage_line = []\n",
        "for i in range(0,3270):\n",
        "  passage_line = \"\"\n",
        "  sentences = sent_tokenize(passages_dev[i])\n",
        "  for sent in sentences:\n",
        "    if any(word in sent for word in array[i]):\n",
        "      passage_line += sent\n",
        "  #print(passage_line)\n",
        "  double_passage_line.append(passage_line)\n",
        "\n",
        "print(len(double_passage_line))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpw2ml65NVKP"
      },
      "source": [
        "#print(passages_train[0])\n",
        "#print(questions_train[0])\n",
        "\n",
        "rows, cols = (3270, 2) \n",
        "\n",
        "arr=[]\n",
        "for i in range(rows):\n",
        "  row = []\n",
        "  for j in range(cols):\n",
        "    if j==0:\n",
        "      tokenize_word = word_tokenize(questions_dev[i])\n",
        "      tagged = nltk.pos_tag(tokenize_word)\n",
        "      row.append(tagged)\n",
        "    else:\n",
        "      #tokenize_word = double_passage_line[i]\n",
        "      tokenize_word = word_tokenize(double_passage_line[i])\n",
        "      #tagged = nltk.pos_tag(tokenize_word)\n",
        "      row.append(tokenize_word)\n",
        "  arr.append(row)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK6XsAUxNVNN",
        "outputId": "f5f47b9b-f288-422d-a75b-75787a2c2634"
      },
      "source": [
        "print(arr[0])"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('does', 'VBZ'), ('ethanol', 'VB'), ('take', 'VB'), ('more', 'JJR'), ('energy', 'NN'), ('make', 'VBP'), ('that', 'IN'), ('produces', 'NNS')], ['The', 'total', 'amount', 'of', 'energy', 'input', 'into', 'the', 'process', 'compared', 'to', 'the', 'energy', 'released', 'by', 'burning', 'the', 'resulting', 'ethanol', 'fuel', 'is', 'known', 'as', 'the', 'energy', 'balance', '(', 'or', '``', 'energy', 'returned', 'on', 'energy', 'invested', \"''\", ')', '.Figures', 'compiled', 'in', 'a', '2007', 'report', 'by', 'National', 'Geographic', 'Magazine', 'point', 'to', 'modest', 'results', 'for', 'corn', 'ethanol', 'produced', 'in', 'the', 'US', ':', 'one', 'unit', 'of', 'fossil-fuel', 'energy', 'is', 'required', 'to', 'create', '1.3', 'energy', 'units', 'from', 'the', 'resulting', 'ethanol.The', 'energy', 'balance', 'for', 'sugarcane', 'ethanol', 'produced', 'in', 'Brazil', 'is', 'more', 'favorable', ',', 'with', 'one', 'unit', 'of', 'fossil-fuel', 'energy', 'required', 'to', 'create', '8', 'from', 'the', 'ethanol.Energy', 'balance', 'estimates', 'are', 'not', 'easily', 'produced', ',', 'thus', 'numerous', 'such', 'reports', 'have', 'been', 'generated', 'that', 'are', 'contradictory.For', 'instance', ',', 'a', 'separate', 'survey', 'reports', 'that', 'production', 'of', 'ethanol', 'from', 'sugarcane', ',', 'which', 'requires', 'a', 'tropical', 'climate', 'to', 'grow', 'productively', ',', 'returns', 'from', '8', 'to', '9', 'units', 'of', 'energy', 'for', 'each', 'unit', 'expended', ',', 'as', 'compared', 'to', 'corn', ',', 'which', 'only', 'returns', 'about', '1.34', 'units', 'of', 'fuel', 'energy', 'for', 'each', 'unit', 'of', 'energy', 'expended.A', '2006', 'University', 'of', 'California', 'Berkeley', 'study', ',', 'after', 'analyzing', 'six', 'separate', 'studies', ',', 'concluded', 'that', 'producing', 'ethanol', 'from', 'corn', 'uses', 'much', 'less', 'petroleum', 'than', 'producing', 'gasoline', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LLkgkMBOb2s",
        "outputId": "d5f840a8-ec72-4c07-abcd-6fe84d7d3993"
      },
      "source": [
        "feature_matrix_dev = [[0,0,0,0,0,0]]\n",
        "for i in range(0,3270):\n",
        "    a = np.array(feature_matrix_dev)\n",
        "    b = np.array([features(arr[i],i)])\n",
        "    #print(a)\n",
        "    #print(b)\n",
        "    feature_matrix_dev = np.concatenate((a,b), axis=0)\n",
        "feature_matrix_dev = feature_matrix_dev[1:]\n",
        "print(len(feature_matrix_dev))\n",
        "print(feature_matrix_dev[3000:3020])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3270\n",
            "[[0 0 0 0 0 1]\n",
            " [0 0 1 0 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 1 1 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 1 1]\n",
            " [0 0 0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkzdok6AOtWS",
        "outputId": "7b83dbd7-88a6-47ea-91d2-52cdb6ff0d7f"
      },
      "source": [
        "#model5 is the Bidirectional Lstm applied with 1 embedding layer, 2 bidirectional layers and 1 output layer\n",
        "inputs5 = keras.Input(shape=(6,), dtype=\"int32\")\n",
        "x5 = layers.Embedding(9427, 6)(inputs5)\n",
        "x5 = layers.Bidirectional(layers.LSTM(50, return_sequences=True))(x5)\n",
        "x5 = layers.Bidirectional(layers.LSTM(50))(x5)\n",
        "outputs5 = layers.Dense(2, activation=\"softmax\")(x5)\n",
        "model5 = keras.Model(inputs5, outputs5)\n",
        "model5.summary()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 6)]               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 6, 6)              56562     \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 6, 100)            22800     \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 139,964\n",
            "Trainable params: 139,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9DYJpmwO7QU"
      },
      "source": [
        "model5.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra4-qtRZPFRC",
        "outputId": "aa00688b-7527-4d1e-b3ec-fb16f301c85f"
      },
      "source": [
        "model5.fit(\n",
        "  feature_matrix,\n",
        "  to_categorical(answers_train),\n",
        "  epochs=15,\n",
        "  batch_size=32\n",
        ")"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "295/295 [==============================] - 10s 14ms/step - loss: 0.6684 - accuracy: 0.6145\n",
            "Epoch 2/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6661 - accuracy: 0.6157\n",
            "Epoch 3/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6603 - accuracy: 0.6251\n",
            "Epoch 4/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6597 - accuracy: 0.6273\n",
            "Epoch 5/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6580 - accuracy: 0.6259\n",
            "Epoch 6/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6603 - accuracy: 0.6236\n",
            "Epoch 7/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6641 - accuracy: 0.6156\n",
            "Epoch 8/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6574 - accuracy: 0.6218\n",
            "Epoch 9/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6562 - accuracy: 0.6240\n",
            "Epoch 10/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6599 - accuracy: 0.6216\n",
            "Epoch 11/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6590 - accuracy: 0.6236\n",
            "Epoch 12/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6546 - accuracy: 0.6294\n",
            "Epoch 13/15\n",
            "295/295 [==============================] - 4s 15ms/step - loss: 0.6561 - accuracy: 0.6244\n",
            "Epoch 14/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6593 - accuracy: 0.6181\n",
            "Epoch 15/15\n",
            "295/295 [==============================] - 4s 14ms/step - loss: 0.6623 - accuracy: 0.6135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54c0523c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQYHEwtPfTe",
        "outputId": "93ecc680-9798-4955-9f31-2229c096085a"
      },
      "source": [
        "model5.evaluate(\n",
        "  feature_matrix_dev,\n",
        "  to_categorical(answers_dev)\n",
        ")"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103/103 [==============================] - 2s 4ms/step - loss: 0.6569 - accuracy: 0.6275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6569253206253052, 0.6275229454040527]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCXR0v0iQcaJ"
      },
      "source": [
        "predictions5 = model5.predict(feature_matrix_dev)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK8cNEGrQncn",
        "outputId": "889d0b39-e520-43b0-f2f6-c195ed923087"
      },
      "source": [
        "y_pred5 = np.argmax(predictions5, axis=1)\n",
        "y_pred5[0:30]"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGpB58qf1zf",
        "outputId": "5cd9eb89-8031-4124-d331-ce6795febed0"
      },
      "source": [
        "#model is the model containing 1 embedding layer, 1 lstm layer, 2 dense relu layers, 1 output layer with sigmoid activation function\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=9427, output_dim=64))\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(100))\n",
        "model.add(layers.Dense(20, activation=\"relu\"))\n",
        "model.add(layers.Dense(10, activation=\"relu\"))\n",
        "model.add(layers.Dense(2, activation=\"sigmoid\"))\n",
        "model.summary()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 64)          603328    \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 20)                2020      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 671,580\n",
            "Trainable params: 671,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA7VvOfqgTN5"
      },
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmNRlkWqgXMW",
        "outputId": "5aa21fdc-af81-43f5-b7d6-279b3c06aae3"
      },
      "source": [
        "model.fit(\n",
        "  feature_matrix,\n",
        "  to_categorical(answers_train),\n",
        "  epochs=20,\n",
        "  batch_size=16\n",
        ")"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "590/590 [==============================] - 10s 14ms/step - loss: 0.6682 - accuracy: 0.6305\n",
            "Epoch 2/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6585 - accuracy: 0.6354\n",
            "Epoch 3/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6585 - accuracy: 0.6239\n",
            "Epoch 4/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6562 - accuracy: 0.6298\n",
            "Epoch 5/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6574 - accuracy: 0.6266\n",
            "Epoch 6/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6542 - accuracy: 0.6300\n",
            "Epoch 7/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6580 - accuracy: 0.6224\n",
            "Epoch 8/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6626 - accuracy: 0.6138\n",
            "Epoch 9/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6557 - accuracy: 0.6279\n",
            "Epoch 10/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6557 - accuracy: 0.6270\n",
            "Epoch 11/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6590 - accuracy: 0.6175\n",
            "Epoch 12/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6546 - accuracy: 0.6296\n",
            "Epoch 13/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6573 - accuracy: 0.6201\n",
            "Epoch 14/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6594 - accuracy: 0.6220\n",
            "Epoch 15/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6549 - accuracy: 0.6253\n",
            "Epoch 16/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6562 - accuracy: 0.6272\n",
            "Epoch 17/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6598 - accuracy: 0.6208\n",
            "Epoch 18/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6584 - accuracy: 0.6231\n",
            "Epoch 19/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6593 - accuracy: 0.6178\n",
            "Epoch 20/20\n",
            "590/590 [==============================] - 8s 14ms/step - loss: 0.6587 - accuracy: 0.6203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54b2c10810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdB2kHvng_DC",
        "outputId": "533a5781-f46a-4267-df27-8e7f5485b561"
      },
      "source": [
        "model.evaluate(\n",
        "  feature_matrix_dev,\n",
        "  to_categorical(answers_dev)\n",
        ")"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103/103 [==============================] - 1s 3ms/step - loss: 0.6575 - accuracy: 0.6229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6575310826301575, 0.6229357719421387]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_t9LZtehRhV"
      },
      "source": [
        "predictions = model.predict(feature_matrix_dev)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB5MpO5Khi42"
      },
      "source": [
        "y_pred = np.argmax(predictions, axis=1)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YHKzJeNhm9Y",
        "outputId": "ec97e6ae-7256-4d06-d496-7d176c625152"
      },
      "source": [
        "y_pred[3000:3200]"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH7oHkNjnB8s",
        "outputId": "964b2e6a-aec1-4a78-9c84-3e5aad725cd0"
      },
      "source": [
        "#f1 score for both the models\n",
        "from sklearn.metrics import f1_score\n",
        "score_lstm = f1_score(y_pred, answers_dev, average='weighted')\n",
        "score_bidirectional = f1_score(y_pred5, answers_dev, average='weighted')\n",
        "print(\"f1 score for bidirectional LSTM\", score_bidirectional)\n",
        "print(\"f1 score for LSTM\", score_lstm)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score for bidirectional LSTM 0.7185796904685458\n",
            "f1 score for LSTM 0.7271327505486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT08Fb87oBSY",
        "outputId": "9b418609-bf68-4111-bcd8-536e27c2d5a7"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "sF-6WBqWnxQN",
        "outputId": "8e857df8-70ab-43c2-d1c1-f0b01e4d9e97"
      },
      "source": [
        "#plotting Roc curve for both the models\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt1\n",
        "from sklearn.metrics import roc_curve\n",
        "arr_dev = []\n",
        "arr_pred = []\n",
        "arr_predict = []\n",
        "for i in range(3270):\n",
        "  arr_dev.append(answers_dev[i])\n",
        "  arr_pred.append(y_pred[i])\n",
        "  arr_predict.append(y_pred5[i])\n",
        "\n",
        "print(len(arr_dev), len(arr_pred))\n",
        "#print(arr_dev.shape, arr_pred.shape)\n",
        "#y_true = # ground truth labels\n",
        "#y_probas = # predicted probabilities generated by sklearn classifier\n",
        "fpr, tpr, thresholds = roc_curve(arr_dev, arr_pred)\n",
        "fpr1, tpr1, thresholds = roc_curve(arr_dev, arr_predict)\n",
        "plt.plot(fpr1, tpr1)\n",
        "#plt.show()\n",
        "plt1.plot(fpr, tpr)\n",
        "#plt1.show()"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3270 3270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f54afddcc90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVeL/8fdJp4Rm6L0jUiUUURTpogIrFmCxsrL2r4LYQHDFvlbWBipFkRJ6kFAURRAEiZAQEloILRA6BJJA6vn9Mdn9ZVk0ASa5mcnn9Tw8z8zcw9zPccLHkzsz9xprLSIi4vl8nA4gIiLuoUIXEfESKnQRES+hQhcR8RIqdBERL+Hn1I5DQkJsvXr1nNq9iIhH+v33349baytfbJtjhV6vXj0iIyOd2r2IiEcyxuz7o2065CIi4iVU6CIiXkKFLiLiJVToIiJeQoUuIuIl8i10Y8xkY8xRY8zWP9hujDETjDHxxpgtxphr3R9TRETyU5AV+lSgz59svwVonPtnOPDZlccSEZFLlW+hW2tXAyf/ZEh/4Gvrsh6oYIyp7q6AIiLeYs+uWH796ln2xBXOd3Dc8cWimsCBPPcTcx9LunCgMWY4rlU8derUccOuRUSKt90HDxO/agbVEubROnsrda1hY3Bl6jcPdfu+ivSbotbaScAkgNDQUF1ZQ0S8UvyRs2z+JYJy28O4IWMNDU06Sb412NToSerc/CAdazYslP26o9APArXz3K+V+5iISImx+1gKq3/bhG/MLG5K+567fI5yzpTiQM2+hHR5iOrNulDdmELN4I5CDweeMMbMAjoCydba/zncIiLibRKOpbB88x7ORs2n89nl3O8Th4+xHArpwOn2Y6nQ7g6aBJQpsjz5FroxZibQFQgxxiQC4wB/AGvt50AE0BeIB9KABwsrrIiI0/YcT2VJ9EESolbR/lQEQ33XE2zOcbZsTVLbPEtwh3upUbGuI9nyLXRr7eB8tlvgcbclEhEpZvYeT2VJTBLro2JoeXwpA31X09AnicyAIDKb9YMO9xNcpzP4OPtdTcdOnysiUpztO+Eq8RXR+6h95Efu9F3NI75b8fXPIb1mJwh9Gf/m/fAPDHY66n+o0EVEcu0/kcaSmCSWxBziyMF9POW3gOn+6ykbkEJWcE182z4LbQYTWKmB01EvSoUuIiXagZO5Jb4liZiDyYDlqcpRPFZ2IoE2HXPNAGgzBL96Nzp+SCU/KnQRKXGOp6Qz7/dElsQksSUxGYDWtSswvkdlBh56j9IJy6BWexjwGYQ0djhtwanQRaREWbIliTELYziVlknrWuV58ZZm9G1RjdqHlkLEKMhIhZ7j4brHwcfX6biXRIUuIiXC6bQMxi6KJTz6EK1rlWfW8NY0rRYMKcdgySOwLRxqtnOtyis3dTruZVGhi4jXW7XjKM/P28KJlAxG9GzCY10b4ufrA1vnQ8SzkH4WerwC1z0Jvp5bi56bXEQkH6npWbwesY0ZG/bTuEpZvrq/PS1qlofU47BkJMQthBrXulblVZo5HfeKqdBFxCtt3HuSkWHRHDiVxvAbGzCiZxOC/H0hbhF8NwLOJ0P3sdD5/zx6VZ6Xd8xCRCTX+cxsPvh+J5PWJFCrYilmD7+ODvUrQeoJWPgsxM6H6m3g/sVQtbnTcd1KhS4iXmPrwWRGhEWx80gKgzvUYfStV1M20A+2LYbvnoFzp+HmMXDD0+Dr73Rct1Ohi4jHy8rO4dNVu5mwcheVygQw5cH23Ny0CqSdhHnPQcwcqNYS7l0I1Vo4HbfQqNBFxKPFH01hZFgU0YnJ9Gtdg1f7X0OF0gGwfQksfhrOnYSuL0GXEV65Ks9LhS4iHiknxzJ13V7eXradUgG+fDykLbe1quFalc9/AbbMhqotYeg8qN7K6bhFQoUuIh4n8VQao+Zs4deEE3RrVoW37mhJlXJBsGMZLP4/SDsON70AXUaCX4DTcYuMCl1EPIa1ljm/J/Lq4jistbw9sCV3h9bGnE+GBc9A9Ayocg0MmQ012jgdt8ip0EXEIxw9e56X5sfww7ajdKxfiXfvak3tSqVh5wpY/BSkHIUbR8GNz5WoVXleKnQRKfYiYpIYvSCG1Ixsxtx6NQ9dXx+f9GRYOAqipkPlq2HQDKh5rdNRHaVCF5FiKzktk3HhW1kYdYhWtcrz/t2taVQlGHb9AOFPQsph13Hym54Hv0Cn4zpOhS4ixdLqncd4bu4Wjqek83SPxjx+cyP8M8/Coidg8zdQuRkMmu46Q6IAKnQRKWbSMrJ4I2Ib09e7Tqj1xX2htKxVHnb/CIuehLOH4PqnoeuL4B/kdNxiRYUuIsVG5N6TjJwTzf6TaTzcpT4jezUlKCfN9VHE36dCSBMY9j3UCnU6arGkQhcRx6VnZfPB97uYtHo3NSqUYtbDnejY4CrY/ZPrWHlyInR+Cm5+CfxLOR232FKhi4ijYg8lMzIsmu2HzzK4Q21G39qcspxznUwrcjJc1QiGrYDaHZyOWuyp0EXEEVnZOXz+824+WrmLCqUDmPJAe25uVgX2rIZFj8PpA3DdE9BtjFblBaRCF5Eil3AshRFh0UQdOM1traozvn8LKvplwJJnYeMXUKkBPLQM6nRyOqpHUaGLSJHJybF8/ete3lq2nUA/XyYMbku/1jVg7y+w8DE4vR86PQbdXoaA0k7H9TgqdBEpEgdPn2PUnGjW7T5B16aVeXtgK6oGZcPS52HD51CxPjwYAXU7Ox3VY6nQRaRQWWuZt+kg/wiPJcda3ryjJYPa18bs/9W1Kj+1Bzr8HXqMg4AyTsf1aCp0ESk0x1PSeXF+DN/HHaFDPdcJteoEA8tfgvWfQcW68MASqHeD01G9ggpdRArFsq1JvLRgKynpWYzuezUP3VAf38QN8O1jcHI3tH8YerwCgWWdjuo1ClToxpg+wEeAL/CltfatC7bXAaYBFXLHvGCtjXBzVhHxAMnnMvlHeCzzNx+kRc1yvH93G5pU8oPvx8Cvn0CF2nD/Yqh/o9NRvU6+hW6M8QU+AXoCicBGY0y4tTYuz7AxQJi19jNjTHMgAqhXCHlFpBhbs8t1Qq2jZ9N5qntjnuzWCP9DkfD5o3AiHkIfgp6vQmCw01G9UkFW6B2AeGttAoAxZhbQH8hb6BYol3u7PHDInSFFpHhLy8jizYjtfLN+Hw0rl2H+o51pXS0QVo51rcrL1YT7FkGDrk5H9WoFKfSawIE89xOBjheMeQVYYYx5EigD9LjYExljhgPDAerUqXOpWUWkGPp930lGhkWz72Qaw26oz6jeTQk6shkmPgrHd0K7B6DneAgql+9zyZVx15uig4Gp1tr3jDHXAd8YY1pYa3PyDrLWTgImAYSGhlo37VtEHJCelc2HP+xi4s+7qV6+FDP+1onr6pSBVa/CugkQXAOGzodG3Z2OWmIUpNAPArXz3K+V+1hew4A+ANbaX40xQUAIcNQdIUWkeIk7dIYRYVFsP3yWe0JrM+a2qwk+sQUmPQbHtsO190Gv1yCovNNRS5SCFPpGoLExpj6uIh8EDLlgzH6gOzDVGHM1EAQcc2dQEXFeVnYOE1cn8OEPOylfKoCv7g+le+MK8POb8MuHULYq/HUeNL7oUVcpZPkWurU2yxjzBLAc10cSJ1trY40xrwKR1tpwYCTwhTHmGVxvkD5grdUhFREvsud4KiPCoti8/zS3tqzO+AEtqJQcC5MGwNE4aDMUer8OpSo4HbXEKtAx9NzPlEdc8NjYPLfjgOvdG01EioOcHMs36/fx5tJtBPr58tGgNvRrEYJZ/Q6seR/KVoEhc6BJL6ejlnj6pqiI/KFDp8/x3Nwt/BJ/nJuaVOadO1tRNWU7TLoLjsZC6yHQ5w0oVdHpqIIKXUQuwlrL/E0HeWVxLNk5ltf/0oIh7aph1rwHa96D0iEweDY07eN0VMlDhS4i/+V4SjovzY9hRdwR2teryLt3taZuZgJ88Vc4EgOt7oE+b0HpSk5HlQuo0EXkP5ZtPczoBTGcPZ/FS32bMey62viu/QBWvwOlKsGgGdDsVqdjyh9QoYuI64Rai2OZv+kg19Qox4yH29CUffBVdzi8BVreBbe8o1V5MadCFynhftl1nFFzo10n1OrWiCduqkfA+gnw89uujyDeMx2uvt3pmFIAKnSREupcRjZvLd3GtF/30aByGeY92pk2AYdgai9IioIWA+GWf0KZq5yOKgWkQhcpgTbtP8XIsGj2HE/lwevr8XyvRgT99jGsegsCy8HdX0Pz/k7HlEukQhcpQTKycvjwh518/u8Taj3ckc7Bx2FaHzi0CZoPgFvfgzIhTkeVy6BCFykhtiWdYURYNNuSznB3aC1e7tuE4E2fw4w3IKAs3DkFWtzhdEy5Aip0ES+XnWOZuHo3H3zvOqHWl/eF0qNyMnx7GxyMhKv7wa3vQ9nKTkeVK6RCF/Fie46nMjIsik37T9O3ZTVe69ecSlsmwbzXIaA0DPzK9eanMU5HFTdQoYt4IWst09fv442I7fj7GtcJtWqmYmb3g8TfoNltrlV5cFWno4obqdBFvExSsuuEWmt2HefGJpV55y/XUG3bFJg4HvyC4I4voeWdWpV7IRW6iJew1rJg80HGhceSlW15bUAL/tooEzP/DjiwHprcArd/CMHVnI4qhUSFLuIFTqSkM3rBVpbFHia0bkXeu6sldeOnw+f/AL8A+MtE10m1tCr3aip0EQ+3IvYwLy2I4cy5LF64pRkPXwO+4XfD/nXQpA/c9iGUq+50TCkCKnQRD3XmfCb/CI9j3qZEmlcvx/RhLWm2fzZ8Pg58A2DAZ9B6sFblJYgKXcQDrYs/zrNzojl85jxPdmvEk239Cfjur7DvF2jUE/pNgHI1nI4pRUyFLuJBzmVk8/ay7Uxdt5cGIWWY90gn2h6ZD5PGgY8v9PsY2g7VqryEUqGLeIjNuSfUSjieygOd6/FCp9IERdwPe9dAw+6uVXn5Wk7HFAep0EWKuYysHCas3MWnq+JdJ9Qa1p7Op8Phi7FgfOD2CXDtfVqViwpdpDjbcfgsz8yOIi7pDHe2q8W4G4MJXvY32PMzNOjqOsRSobbTMaWYUKGLFEPZOZYv1iTw/oqdlCvlxxf3tqPnuaXw1RjXgNs+hHYPaFUu/0WFLlLM7DuRysiwaCL3naLPNdV4s3sFKv7wCCT8BPVvdK3KK9Z1OqYUQyp0kWLCWsu3G/bzRsQ2fH0MH9zdigH2R8zU0WBzXBeeaPcQ+Pg4HVWKKRW6SDFwOPk8z83bwuqdx+jSOIR3e4dQddXTEP8D1OsC/T+GivWcjinFnApdxEHWWhZFHWLsoq1kZlvG97+GoYFrMN/cBTmZ0PddCB2mVbkUiApdxCEnUzMYszCGiJjDtKtbkQ9vqULttaNg1wqoe71rVV6pgdMxxYOo0EUc8EPcEV6YH8OZc5k837spf6+wAZ+ZgyA7A/q8DR2Ga1Uul6xAPzHGmD7GmB3GmHhjzAt/MOZuY0ycMSbWGDPDvTFFvMPZ85mMmhPN376OpHJwIBEPNeTRpNH4LHoMqjaHR9dCp0dU5nJZ8l2hG2N8gU+AnkAisNEYE26tjcszpjHwInC9tfaUMaZKYQUW8VTrdh9n1JwtJCWf4/GuDXimahR+c4ZCVjr0fhM6/t11PhaRy1SQQy4dgHhrbQKAMWYW0B+IyzPmYeATa+0pAGvtUXcHFfFU5zNdJ9SasnYv9UPKsPD+RrTa/Aqsj4DaHaH/pxDSyOmY4gUKUug1gQN57icCHS8Y0wTAGLMW8AVesdYuu/CJjDHDgeEAderUuZy8Ih4l6sBpRoRFkXAslQeuq8tLdWIJWPQAZJ6DXq9Dp0e1Khe3cdebon5AY6ArUAtYbYxpaa09nXeQtXYSMAkgNDTUumnfIsVORlYOH/+4i09W7aZqcCBhf21Ih9jxsOg7qNXedfGJkMZOxxQvU5BCPwjkPftPrdzH8koENlhrM4E9xpiduAp+o1tSiniQHYfPMiIsithDZxjYtibjm+ykdMTfICMVer4K1z2hVbkUioIU+kagsTGmPq4iHwQMuWDMQmAwMMUYE4LrEEyCO4OKFHfZOZYv1yTw3oqdBAf5MeWuetwc/xYsCoea7Vyr8spNnY4pXizfQrfWZhljngCW4zo+PtlaG2uMeRWItNaG527rZYyJA7KBUdbaE4UZXKQ42X8ijZFzoti49xS9r6nKP5vvodzKv0P6Weg+Djo/Bb762ocULmOtM4eyQ0NDbWRkpCP7FnEXay0zftvP60tcJ9R6s3d1bk18HxO7AGq0da3Kq1ztdEzxIsaY3621oRfbpiWDyGU6nHye5+dt4eedx7ihUQgTWu+n0k+Pwflk6PYyXP+0VuVSpPTTJnKJrLWERx9i7KJY0rOyefuWmtx9dAJmyTyo3hruD4eq1zgdU0ogFbrIJTiZmsHLC7eyJCaJtnUq8HloElV/vgvOnYKbx8ANT4Ovv9MxpYRSoYsU0MptR3h+XgzJ5zIY060aD535DJ+IOVCtJdy7AKq1cDqilHAqdJF8nD2fyWvfbWN25AGaVQtmfrfT1Fk3GNJOQNeXoMsIrcqlWFChi/yJX3ef4Nk50SQln+PpGyrzZPqX+K6YDVVbwF/nQvVWTkcU+Q8VushFnM/M5p1lO5i8dg/1rirNilvTaLT+Xkg9Bjc9D12eBb8Ap2OK/BcVusgFtiSe5pnZUew+lsrw9pV4jqn4/TALqlwDQ2ZDjTZORxS5KBW6SK7M7Bz+9WM8n/wUT+WygXzX5xwtfn8IUo64VuQ3PQd+gU7HFPlDKnQRYOcR1wm1th48w5BW5XklcAYBq76FylfDoG+h5rVORxTJlwpdSrTsHMvkX/bwzxU7KBvox9weqYRuGQVnk+CGEdD1Ba3KxWOo0KXE2n8ijWfnRPPb3pPc3qws7wSHUeqX6RDSFIb9ALXaOR1R5JKo0KXEsdYy87cDvLYkDl9j+LprKl3insPsO+Q6/0rXF8E/yOmYIpdMhS4lypEzrhNqrdpxjO4NSjHhqgWUWf81XNUYHloBtds7HVHksqnQpcQIjz7Eywu3kp6VzcTOZ+m1+3nMoUTo/CTcPBr8SzkdUeSKqNDF651KzWDMoq0s2ZJEp1qBTKy2mPKbvoarGsFDy6HOhdc8F/FMKnTxaj9tP8pz87ZwOi2DDzucof/+NzBbD7iu69ltjFbl4lVU6OKVUtKzeO27OGZtPECrKv4sa7Kcq7ZMhUoN4MGlUPc6pyOKuJ0KXbzO+gTXCbUOnT7H623PMCTpLUzsPuj4KHQfCwGlnY4oUihU6OI1zmdm8+7yHXy1dg9NKvrwa5sVVN02FSrWgweWQL3rnY4oUqhU6OIVYhKTeSYsivijKYxucYphJ97DZ1sCdPg79BgHAWWcjihS6FTo4tEys3P45Kd4Pv4xnppl4JfWK6i1YxpUqAP3fwf1uzgdUaTIqNDFY8UfPcuIsGi2JCbzTNNTPHHmPXx3JED7h6HHKxBY1umIIkVKhS4eJyfHMnntHt5ZvoNK/ln82HIlDXZNhfK14b5waHCT0xFFHKFCF49y4KTrhFob9pxkeP0TPHf+I/x2xUPoQ9DzVQgMdjqiiGNU6OIRrLWERR7g1cVxBJpMll3zI00TpmLK1YR7F0LDm52OKOI4FboUe0fPnOeF+TH8uP0oQ2sdY1zOx/jv3gXtHoCe4yGonNMRRYoFFboUa99tOcSYhVvJyjhPeLOfaLlvKia4BgydD426Ox1PpFhRoUuxdDotg5cXxbI4+hADqx3lDfMpgXt3Qtt7offrEFTe6YgixY4KXYqdn3Yc5fm5W0hJTWVO458ITfwaU7Yq/HUuNO7pdDyRYkuFLsVGanoWry3Zxszf9nNryBHeK/s5QQd2QJuhrlV5qQpORxQp1gpU6MaYPsBHgC/wpbX2rT8YNxCYC7S31ka6LaV4vd/2nGTknCiOnDrL9IaruP7QNEzZKjBkDjTp5XQ8EY+Qb6EbY3yBT4CeQCKw0RgTbq2Nu2BcMPB/wIbCCCre6XxmNu9/v5Mv1iTQrfxhllebROmD26H1YOjzJpSq6HREEY9RkBV6ByDeWpsAYIyZBfQH4i4YNx54Gxjl1oTitbYeTGZEWBR7jpzmy7o/0e3YNxi/q2DwLGh6i9PxRDyOTwHG1AQO5LmfmPvYfxhjrgVqW2uX/NkTGWOGG2MijTGRx44du+Sw4h2ysnOYsHIXAz5ZS5XUXWyq9ibdj0zBtBgIj61XmYtcpit+U9QY4wO8DzyQ31hr7SRgEkBoaKi90n2L54k/msLIsChiE0/wUa1V9D35NSazEgyaAc1udTqeiEcrSKEfBGrnuV8r97F/CwZaAKuMMQDVgHBjTD+9MSr/lpNjmbJuL+8s204r/0R+rzaZ8sfjoOVdcMs7ULqS0xFFPF5BCn0j0NgYUx9XkQ8Chvx7o7U2GQj5931jzCrgWZW5/NuBk2mMmhvNxoRj/LPaj/zlzHRMZgW4ZzpcfbvT8US8Rr6Fbq3NMsY8ASzH9bHFydbaWGPMq0CktTa8sEOKZ7LWMicykVe/i6MhB9hYdTKVTsfCNXdA33ehzFVORxTxKgU6hm6tjQAiLnhs7B+M7XrlscTTHT17nhfnxbBqexKvVV7JoNQZmMxguGsaXDPA6XgiXknfFBW3i4hJYvSCGKpn7GN9lSlUPhMLzftD3/egbGWn44l4LRW6uE1yWiZjw7eyOCqRsZVWcp+ZgU9mGbhzCrS4w+l4Il5PhS5u8fPOYzw3N5ryKXtYW3ka1c/GuN7wvPV9KFvF6XgiJYIKXa5IanoWb0RsY+aGvTxffiUPl5qBT1ZpGPgVtBgIro+yikgRUKHLZdu49yQjw6LxO72b1SFTqZUSA01vhds+gOCqTscTKXFU6HLJzmdm88H3O/lyTTxPl13J46Vm4JNVCu74wvVFIa3KRRyhQpdL8u8TamUc3cXKilOplxYDTW6B2z+E4GpOxxMp0VToUiBZ2Tl8tmo3E1bu4JGgH3i69Ex8cwLhLxOh1T1alYsUAyp0ydfuYymMCIvmVOIOllaYSqNz0dC4N9z+EZSr7nQ8EcmlQpc/lJNjmfbrXt5eGscD/j/wbOmZ+OUEQP9Poc0QrcpFihkVulxU4qk0Rs3ZQuKeOBaWm0Kz9C1QvwfcPgHK18z/CUSkyKnQ5b9Ya5nzeyLjF2/lbruCr0vPxA9/6PcxtB2qVblIMaZCl/84djadF+fHsH37VmYET6FlRhTU6wb9/gXlazkdT0TyoUIXAJbmnlDr1szlfFp6Bv74ug6vXHufVuUiHkKFXsIlp2UyLnwrG6OimRw8hTY5UVC3q+sQS4Xa+f59ESk+VOgl2Oqdx3huTjTdzy3lxzIzCTDG9bX9dg9qVS7igVToJVBahuuEWivXb+bjMpMJ9dsMdW50rcor1nU6nohcJhV6CRO59yQjw6LolBzBT2VmEOgD9H4XQoeBj4/T8UTkCqjQS4j0rGw++H4X4at/4/1Sk+nkvxlqd4H+H0PFek7HExE3UKGXALGHkhk5O4oWx5ewstS3BPnmQO9/Qvu/aVUu4kVU6F4sKzuHz3/ezayVG3gzYDJd/H+HWp1hwCdQqYHT8UTEzVToXirhWAojZkfR4NBiVgRNp5RPNvR4GzoM16pcxEup0L1MTo7lm/X7+HLpOsb7fknXgN+hZicY8Clc1dDpeCJSiFToXuTQ6XOMmhNFyJ5wlgZ9QxmTCT3egI6PgI+v0/FEpJCp0L2AtZZ5mw7ycfhaXmYS3QMisTU7Yvp/CiGNnI4nIkVEhe7hjqek89K8LQTtWMjiwGmU9cmA7q9hOj2mVblICaNC92DLth7mvflrGJU1kV4BG7E1QjEDPoPKTZyOJiIOUKF7oORzmfwjPJb06HnMDZxKsH863PwPTOcntSoXKcFU6B5mza5jvDFnDU+e/5y+ARvIqd4OnwGfQpVmTkcTEYep0D1EWkYWby3dzrENYcwInEp5v3Nw8zh8Oj8FvnoZRQQK9A0TY0wfY8wOY0y8MeaFi2wfYYyJM8ZsMcasNMbolH1u9Pu+Uwz+cAntI0fyWcBHlK9aH59HVkOXESpzEfmPfNvAGOMLfAL0BBKBjcaYcGttXJ5hm4FQa22aMeZR4B3gnsIIXJKkZ2Xz0Q+72LNmJlP8p1DBPw26vozP9U+ryEXkfxSkFToA8dbaBABjzCygP/CfQrfW/pRn/HpgqDtDlkTbks4wduZqhp76hOf815FdtRU+d3wOVa9xOpqIFFMFKfSawIE89xOBjn8yfhiw9GIbjDHDgeEAderUKWDEkiUrO4eJqxOIWTmDz/y+opJ/Ktw0Gt8bngFff6fjiUgx5tbf240xQ4FQ4KaLbbfWTgImAYSGhlp37tsb7DmeyrhZa/jLkQk87reWrCot8LljIlRr4XQ0EfEABSn0g0DeqwXXyn3svxhjegCjgZustenuiVcy5ORYpm/Yx68R3/Ke7ySu8kvB3vgCfjc+q1W5iBRYQQp9I9DYGFMfV5EPAobkHWCMaQtMBPpYa4+6PaUXO3T6HK+EraX3gQ/5zHcNmSHN8Rk4Eaq3cjqaiHiYfAvdWptljHkCWA74ApOttbHGmFeBSGttOPBPoCwwx7iuFr/fWtuvEHN7PGstCzYf5IfwbxhvJ1LZ7wy2yyj8b3wO/AKcjiciHqhAx9CttRFAxAWPjc1zu4ebc3m1EynpjJ/7K9fHv8enfqvJCGmGz8AFUKOt09FExIPpw8xFbHnsYRbP+5ox2Z9RxT+ZnOufJaDrc+AX6HQ0EfFwKvQicuZ8Jm8v+I2Wse/wsd8q0is1wefOeVDzWqejiYiXUKEXgbXxx5kzexrPZ3xMVb/TZHd+hsBuL2pVLiJupUIvROcysvngu0jqbXqTD/1+4nyFhvjcNRdqtXM6moh4IRV6Idm0/xQzZkzj6XP/oobfSbKue4qgbqPBP8jpaCLipVTobpaRlcOnKzZT5dfXedd3JWnlG+Bz1yx8ard3OpqIeDkVuhttSzrDtG+/5omzH1DD9wQZHR6ndM+Xwb+U09FEpARQobtBdo5l8o9bKfXzP3jL93tSg+vhc/cMAur82TnMRETcS4V+hfYeT8FaS/AAAAfvSURBVOWrb7/h4RPvUsv3OOfbPUKZ3uMgoLTT0USkhFGhXyZrLbN+2Ub2968w3mc5KcF1MHdHEFS3s9PRRKSEUqFfhqTkc3w1fTr3HnmHuj5HSW37MGVveVWrchFxlAr9ElhrWRwZT/KSsbxkl5Japib2niWUqXeD09FERFToBXUiJZ3JM2ZyZ+Ib1Pc5wpnWD1HuttcgoIzT0UREABV6gazcso+kBaMZmfMdKaWrk333Yso1uNHpWCIi/0WF/ifOnM9k2uzZ9N39Gt19kjjV4j4q9nsTAss6HU1E5H+o0P/A+u2JJMx5icezwjlbqhqZdy6iYuOuTscSEflDKvQLnMvI5tt5c7l52zg6+SRxvNkQQu54BwKDnY4mIvKnVOh5RCUksW3mSzyYsYCzQVVIHzifkKbdnY4lIlIgKnRcJ9QKW7SIjtGjGexzkMON76Hane9CUDmno4mIFFiJL/SdB4+z+ZsXGHxuLmcDQki9I4xqzXs7HUtE5JKV2ELPzrEsXPIdLSNf4B6TyMEGd1LznvchqLzT0URELkuJLPR9R0+ycdqLDEgJ46xfJc70n0nNVn2djiUickVKVKFba1m6YhmN1o3iTnOAfXUGUGfIh5hSFZ2OJiJyxUpMoR8+eYb1U1/ktuQZnPWtwMnbv6Fu235OxxIRcRuvL3RrLat+Xkn1VSMYwD5217ydBkP/hSmtVbmIeBevLvSTZ1JZN/VFep+YTopvOY7cMpWG7f/idCwRkULhtYW+Yd0qKqx4mtvYw86qt9Dw/k/xLVPJ6VgiIoXG6wr9bGoa66aN4eYjU0nxCSax1xc0ue5up2OJiBQ6ryr0qMh1BC15nN42gbiQXjS6/zMqlQtxOpaISJHwikI/n57Oumkvc8PBL0n1KUtCt89pfuNgp2OJiBQpjy/07Vt+g4WP0i0nnq0Vu9Pw/s9oULGq07FERIqcT0EGGWP6GGN2GGPijTEvXGR7oDFmdu72DcaYeu4OeqHMzAzWTH6J+vNuoWrOUbZ3+Rctnp5PKZW5iJRQ+a7QjTG+wCdATyAR2GiMCbfWxuUZNgw4Za1tZIwZBLwN3FMYgQH2bt9E+ty/0yVrJ9HlutLggc9odlWNwtqdiIhHKMgKvQMQb61NsNZmALOA/heM6Q9My709F+hujDHui/n//bZgAtVn9qJqVhJRnT6g9chFBKvMRUQKVOg1gQN57ifmPnbRMdbaLCAZuOrCJzLGDDfGRBpjIo8dO3ZZgcvVaEZs2evIfvRX2vR56LKeQ0TEGxXpm6LW2knAJIDQ0FB7Oc/RrGMv6NjLrblERLxBQVboB4Haee7Xyn3somOMMX5AeeCEOwKKiEjBFKTQNwKNjTH1jTEBwCAg/IIx4cD9ubfvBH601l7WClxERC5PvodcrLVZxpgngOWALzDZWhtrjHkViLTWhgNfAd8YY+KBk7hKX0REilCBjqFbayOAiAseG5vn9nngLvdGExGRS1GgLxaJiEjxp0IXEfESKnQRES+hQhcR8RLGqU8XGmOOAfsu86+HAMfdGMcTaM4lg+ZcMlzJnOtaaytfbINjhX4ljDGR1tpQp3MUJc25ZNCcS4bCmrMOuYiIeAkVuoiIl/DUQp/kdAAHaM4lg+ZcMhTKnD3yGLqIiPwvT12hi4jIBVToIiJeolgXenG8OHVhK8CcRxhj4owxW4wxK40xdZ3I6U75zTnPuIHGGGuM8fiPuBVkzsaYu3Nf61hjzIyizuhuBfjZrmOM+ckYszn357uvEzndxRgz2Rhz1Biz9Q+2G2PMhNz/HluMMdde8U6ttcXyD65T9e4GGgABQDTQ/IIxjwGf594eBMx2OncRzPlmoHTu7UdLwpxzxwUDq4H1QKjTuYvgdW4MbAYq5t6v4nTuIpjzJODR3NvNgb1O577COd8IXAts/YPtfYGlgAE6ARuudJ/FeYVerC5OXUTynbO19idrbVru3fW4riDlyQryOgOMB94GzhdluEJSkDk/DHxirT0FYK09WsQZ3a0gc7ZAudzb5YFDRZjP7ay1q3FdH+KP9Ae+ti7rgQrGmOpXss/iXOhuuzi1BynInPMahuv/8J4s3znn/ipa21q7pCiDFaKCvM5NgCbGmLXGmPXGmD5Flq5wFGTOrwBDjTGJuK6/8GTRRHPMpf57z1eRXiRa3McYMxQIBW5yOkthMsb4AO8DDzgcpaj54Trs0hXXb2GrjTEtrbWnHU1VuAYDU6217xljrsN1FbQW1tocp4N5iuK8Qi+JF6cuyJwxxvQARgP9rLXpRZStsOQ352CgBbDKGLMX17HGcA9/Y7Qgr3MiEG6tzbTW7gF24ip4T1WQOQ8DwgCstb8CQbhOYuWtCvTv/VIU50IviRenznfOxpi2wERcZe7px1Uhnzlba5OttSHW2nrW2nq43jfoZ62NdCauWxTkZ3shrtU5xpgQXIdgEooypJsVZM77ge4AxpircRX6sSJNWbTCgftyP+3SCUi21iZd0TM6/U5wPu8S98W1MtkNjM597FVc/6DB9YLPAeKB34AGTmcugjn/ABwBonL/hDudubDnfMHYVXj4p1wK+DobXIea4oAYYJDTmYtgzs2Btbg+ARMF9HI68xXOdyaQBGTi+o1rGPAI8Eie1/iT3P8eMe74udZX/0VEvERxPuQiIiKXQIUuIuIlVOgiIl5ChS4i4iVU6CIiXkKFLiLiJVToIiJe4v8BKyqo9Ja1pIIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}