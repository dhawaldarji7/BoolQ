{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BoolQ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJhStTYJlFc9"
      },
      "source": [
        "# Libraries and Dependencies"
      ],
      "id": "CJhStTYJlFc9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "intense-butler"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "\n",
        "# install the sentencepiece library\n",
        "# NOTE: if installing for the first time and if using google colab, restart the runtime after installation\n",
        "!pip install sentencepiece"
      ],
      "id": "intense-butler",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3aAqlQIlMzN"
      },
      "source": [
        "# Imports"
      ],
      "id": "T3aAqlQIlMzN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "silver-adobe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import datetime as dt\n",
        "import random\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import RandomSampler, SequentialSampler, TensorDataset, DataLoader\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, BertForSequenceClassification, BertTokenizer,AdamW\n",
        "from transformers import DebertaForSequenceClassification, AlbertForSequenceClassification, ElectraForSequenceClassification\n",
        "from transformers import DebertaTokenizer, AlbertTokenizer, ElectraTokenizer\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "id": "silver-adobe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnNIIO_MldpW"
      },
      "source": [
        "# Pre-trained Models"
      ],
      "id": "OnNIIO_MldpW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hollywood-tongue"
      },
      "source": [
        "# Use GPU if available else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", device)\n",
        "\n",
        "# import the pre-trained models\n",
        "modelB = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "modelR = RobertaForSequenceClassification.from_pretrained(\"roberta-base\").to(device)\n",
        "modelE = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\").to(device)\n",
        "modelA = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\").to(device)\n",
        "modelD = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\").to(device)\n",
        "\n",
        "# Tokenizers to be used\n",
        "tokenizerB = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizerR = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "tokenizerE = ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
        "tokenizerA = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "tokenizerD = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "print(\"Model ready to be fine-tuned!!!\")"
      ],
      "id": "hollywood-tongue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpz5c3awli1P"
      },
      "source": [
        "# Data Loading"
      ],
      "id": "Mpz5c3awli1P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gothic-princeton"
      },
      "source": [
        "# Load the data\n",
        "trainData = pd.read_json(\"./train.jsonl\", lines=True, orient=\"records\")\n",
        "valData = pd.read_json(\"./val.jsonl\", lines=True, orient=\"records\")\n",
        "testData = pd.read_json(\"./test.jsonl\", lines=True, orient=\"records\")\n",
        "\n",
        "# Train \n",
        "trainPassages = trainData.passage.values\n",
        "trainQuestions = trainData.question.values\n",
        "trainAnswers = trainData.label.values.astype(int)\n",
        "\n",
        "# Validation\n",
        "valPassages = valData.passage.values\n",
        "valQuestions = valData.question.values\n",
        "valAnswers = valData.label.values.astype(int)\n",
        "\n",
        "# Test\n",
        "testPassages = testData.passage.values\n",
        "testQuestions = testData.question.values\n"
      ],
      "id": "gothic-princeton",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL_P_tWulmXH"
      },
      "source": [
        "# Tokenization"
      ],
      "id": "vL_P_tWulmXH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lAVCay_I0eN"
      },
      "source": [
        "def tokenizeData(tokenizer, questions, passages, max_length=256):\r\n",
        "    \"\"\"Encode the question/passage pairs into features than can be fed to the model.\"\"\"\r\n",
        "    input_ids = []\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    for question, passage in zip(questions, passages):\r\n",
        "      tokenizedData = tokenizer.encode_plus(question, passage, max_length=max_length, padding='max_length', truncation=\"longest_first\")\r\n",
        "      tokenizedQP = tokenizedData[\"input_ids\"]\r\n",
        "      attentionMask = tokenizedData[\"attention_mask\"]\r\n",
        "\r\n",
        "      input_ids.append(tokenizedQP)\r\n",
        "      attention_masks.append(attentionMask)\r\n",
        "\r\n",
        "    return np.array(input_ids), np.array(attention_masks)\r\n"
      ],
      "id": "2lAVCay_I0eN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-yAgp6hlpUi"
      },
      "source": [
        "# Building Dataloaders"
      ],
      "id": "Q-yAgp6hlpUi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "variable-sport"
      },
      "source": [
        "# Building the Dataloaders\n",
        "\n",
        "def buildDataLoaders(batchSize, trainFeatures, valFeatures, testFeatures):\n",
        "  trainTensors = [torch.tensor(feature, dtype=torch.long) for feature in trainFeatures]\n",
        "  valTensors = [torch.tensor(feature, dtype=torch.long) for feature in valFeatures]\n",
        "\n",
        "  trainDataset = TensorDataset(*trainTensors)\n",
        "  valDataset = TensorDataset(*valTensors)\n",
        "\n",
        "  trainSampler = RandomSampler(trainDataset)\n",
        "  valSampler = SequentialSampler(valDataset)\n",
        "\n",
        "  trainDataloader = DataLoader(trainDataset, sampler=trainSampler, batch_size=batchSize)\n",
        "  valDataloader = DataLoader(valDataset, sampler=valSampler, batch_size=batchSize)\n",
        "\n",
        "  return trainDataloader, valDataloader"
      ],
      "id": "variable-sport",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJoAFVuhltDY"
      },
      "source": [
        "# Fine-Tuning"
      ],
      "id": "uJoAFVuhltDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "united-mississippi"
      },
      "source": [
        "# Fine-tune the model on downstream task: BoolQ\n",
        "def train(numEpochs, gradSteps, model, optimizer, trainDataLoader):\n",
        "    \n",
        "  trainLossHistory = []\n",
        "\n",
        "  for _ in tqdm(range(numEpochs), desc=\"Training Epoch's\"):\n",
        "\n",
        "    # Train the model for fine-tuning\n",
        "    epochTrainLoss = 0 # Cumulative loss\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    for step, batch in enumerate(trainDataLoader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        labels = batch[2].to(device)     \n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss = loss / gradSteps\n",
        "        epochTrainLoss += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        if (step + 1) % gradSteps == 0: # Gradient accumulation is over\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clipping gradients\n",
        "          optimizer.step()\n",
        "          model.zero_grad()\n",
        "\n",
        "    epochTrainLoss = epochTrainLoss / len(trainDataLoader)          \n",
        "    trainLossHistory.append(epochTrainLoss)\n",
        "\n",
        "  sns.set()\n",
        "  plt.plot(trainLossHistory, label=\"Train_Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Training Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks(np.arange(0, 3))\n",
        "  plt.show()"
      ],
      "id": "united-mississippi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v69quqIWiUFV"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "v69quqIWiUFV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Ya4lrVMz8e"
      },
      "source": [
        "# Evaluation on validation set\r\n",
        "def eval(valDataLoader, numEpochs, model):\r\n",
        "    valAccuracy = []\r\n",
        "    valF1 = []\r\n",
        "\r\n",
        "    for _ in tqdm(range(numEpochs), desc=\"Validation Epoch's\"):\r\n",
        "      epochValAcc = 0\r\n",
        "      epochValF1 = 0\r\n",
        "      model.eval()\r\n",
        "      for batch in valDataLoader:\r\n",
        "        input_ids = batch[0].to(device)\r\n",
        "        attention_masks = batch[1].to(device)\r\n",
        "        labels = batch[2]\r\n",
        "                    \r\n",
        "        with torch.no_grad():        \r\n",
        "            outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\r\n",
        "                        \r\n",
        "        logits = outputs[0]\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        \r\n",
        "        predictions = np.argmax(logits, axis=1).flatten()\r\n",
        "        labels = labels.numpy().flatten()\r\n",
        "        epochValF1 += f1_score(predictions, labels)\r\n",
        "        epochValAcc += np.sum(predictions == labels) / len(labels)\r\n",
        "\r\n",
        "      epochValAcc = epochValAcc / len(valDataLoader)\r\n",
        "      epochValF1 = epochValF1 / len(valDataLoader)\r\n",
        "      valAccuracy.append(epochValAcc)\r\n",
        "      valF1.append(epochValF1)\r\n",
        "\r\n",
        "    acc = sum(valAccuracy) / len(valAccuracy)\r\n",
        "    f1 = sum(valF1) / len(valF1)\r\n",
        "    print(\"\\nVal Accuracy:\", acc)\r\n",
        "    print(\"Val F1:\", f1)\r\n",
        "\r\n",
        "    \r\n",
        "    plt.plot(valAccuracy, label=\"Val_Acc\")\r\n",
        "    plt.xlabel(\"Epoch\")\r\n",
        "    plt.ylabel(\"Accuracy\")\r\n",
        "    plt.title(\"Evaluation Accuracy\")\r\n",
        "    plt.legend()\r\n",
        "    plt.xticks(np.arange(0, 3))\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    return acc, f1"
      ],
      "id": "e4Ya4lrVMz8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HppGYFt8lw0i"
      },
      "source": [
        "# Predictions"
      ],
      "id": "HppGYFt8lw0i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVT2HUyG-mYg"
      },
      "source": [
        "# Making Predictions on the test set\r\n",
        "def predict(question, passage, max_length=512):\r\n",
        "  sequence = tokenizer.encode_plus(question, passage, max_length=max_length,\r\n",
        "                                   padding='max_length', truncation=\"longest_first\" \r\n",
        "                                   , return_tensors=\"pt\")['input_ids'].to(device)\r\n",
        "  \r\n",
        "  logits = model(sequence)[0]\r\n",
        "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\r\n",
        "  proba_yes = round(probabilities[1], 2)\r\n",
        "  proba_no = round(probabilities[0], 2)\r\n",
        "  return (f\"Question: {question}, Yes: {proba_yes}, No: {proba_no}\")\r\n",
        "\r\n",
        "# for i in range(len(testPassages)):\r\n",
        "#   testPred.write(f\"\\n{i}\" + \": \" + predict(testQuestions[i], testPassages[i]))\r\n",
        "  \r\n",
        "\r\n"
      ],
      "id": "yVT2HUyG-mYg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcmDenAbmAe2"
      },
      "source": [
        "def runModel(model, tokenizer, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs):\r\n",
        "\r\n",
        "  print(\"Fine-tuning and evaluating the model...\")\r\n",
        "  # Tokenize the data\r\n",
        "  trainIds, trainAttMasks = tokenizeData(tokenizer, trainQuestions, trainPassages, maxSeqLength)\r\n",
        "  valIds, valAttMasks = tokenizeData(tokenizer, valQuestions, valPassages, maxSeqLength)\r\n",
        "  testIds, testAttMasks = tokenizeData(tokenizer, testQuestions, testPassages, maxSeqLength)\r\n",
        "\r\n",
        "  trainFeatures = (trainIds, trainAttMasks , trainAnswers)\r\n",
        "  valFeatures = (valIds, valAttMasks, valAnswers)\r\n",
        "  testFeatures = (testIds, testAttMasks)\r\n",
        "\r\n",
        "  # Build the Dataloaders\r\n",
        "  trainDataLoader, valDataLoader = buildDataLoaders(batchSize, trainFeatures, valFeatures, testFeatures)\r\n",
        "\r\n",
        "  # Fine-tune\r\n",
        "  train(numEpochs, gradSteps, model, optimizer, trainDataLoader)\r\n",
        "\r\n",
        "  # Evaluate\r\n",
        "  acc, f1 = eval(valDataLoader, numEpochs, model)\r\n",
        "\r\n",
        "  # Writing results to a file\r\n",
        "  if model == modelB:\r\n",
        "    results = \"resultsBERT.txt\"\r\n",
        "  elif model == modelR:\r\n",
        "    results = \"resultRoBERTa.txt\" \r\n",
        "  elif model == modelE:\r\n",
        "    results = \"resultELECTRA.txt\"\r\n",
        "  elif model == modelA:\r\n",
        "    results = \"resultALBERT.txt\"\r\n",
        "  elif model == modelD:\r\n",
        "    results = \"resultDeBERTa.txt\"\r\n",
        "  \r\n",
        "  resultFile = open(results, \"w\")\r\n",
        "  resultFile.write(f\"Validation Accuracy: {round(acc, 2)}, Validation F1: {round(f1,2)}\")\r\n",
        "\r\n"
      ],
      "id": "YcmDenAbmAe2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYCakbh5lz9M"
      },
      "source": [
        "# Testing"
      ],
      "id": "RYCakbh5lz9M"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I50RP5kuidSo"
      },
      "source": [
        "print(\"Models Available:\\n 1: BERT \\n 2: RoBERTa \\n 3: ELECTRA \\n 4: ALBERT \\n 5: DeBERTa \\n 6: All\\n\")\r\n",
        "choice = int(input(\"Select the model you'd like to run:\"))\r\n",
        "\r\n",
        "learningRate = float(input(\"Please enter a learning rate:\"))\r\n",
        "batchSize = int(input(\"Please enter batch size:\"))\r\n",
        "numEpochs = int(input(\"Please enter the number of epochs:\"))\r\n",
        "maxSeqLength = int(input(\"Please enter the maximum sequence length:\"))\r\n",
        "gradSteps = int(input(\"Please enter the number of gradient steps:\"))\r\n",
        "\r\n",
        "if choice == 1:\r\n",
        "  print(\"\\nYou have selected the BERT model\")\r\n",
        "  optimizer = AdamW(modelB.parameters(), lr=learningRate)\r\n",
        "  runModel(modelB, tokenizerB, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "elif choice == 2:\r\n",
        "  print(\"\\nYou have selected the RoBERTa model\")\r\n",
        "  optimizer = AdamW(modelR.parameters(), lr=learningRate)\r\n",
        "  runModel(modelR, tokenizerR, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "elif choice == 3:\r\n",
        "  print(\"\\nYou have selected the ELECTRA model\")\r\n",
        "  optimizer = AdamW(modelE.parameters(), lr=learningRate)\r\n",
        "  runModel(modelE, tokenizerE, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "elif choice == 4:\r\n",
        "  print(\"\\nYou have selected the ALBERT model\")\r\n",
        "  optimizer = AdamW(modelA.parameters(), lr=learningRate)\r\n",
        "  runModel(modelA, tokenizerA, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "elif choice == 5:\r\n",
        "  print(\"\\nYou have selected the DeBERTa model\")\r\n",
        "  optimizer = AdamW(modelD.parameters(), lr=learningRate)\r\n",
        "  runModel(modelD, tokenizerD, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "elif choice == 6:\r\n",
        "  print(\"\\nYou have selected to run all models\")\r\n",
        "\r\n",
        "  print(\"\\nNow running BERT\")\r\n",
        "  optimizer = AdamW(modelB.parameters(), lr=learningRate)\r\n",
        "  runModel(modelB, tokenizerB, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "  print(\"\\nNow running RoBERTa\")\r\n",
        "  optimizer = AdamW(modelR.parameters(), lr=learningRate)\r\n",
        "  runModel(modelR, tokenizerR, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "  print(\"\\nNow running ELECTRA\")\r\n",
        "  optimizer = AdamW(modelE.parameters(), lr=learningRate)\r\n",
        "  runModel(modelE, tokenizerE, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "  print(\"\\nNow running ALBERT\")\r\n",
        "  optimizer = AdamW(modelA.parameters(), lr=learningRat)\r\n",
        "  runModel(modelA, tokenizerA, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "  print(\"\\nNow running DeBERTa\")\r\n",
        "  optimizer = AdamW(modelD.parameters(), lr=learningRate)\r\n",
        "  runModel(modelD, tokenizerD, optimizer, batchSize, maxSeqLength, gradSteps, numEpochs)\r\n",
        "\r\n",
        "\r\n"
      ],
      "id": "I50RP5kuidSo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxPHPqLNfWN"
      },
      "source": [
        ""
      ],
      "id": "lbxPHPqLNfWN",
      "execution_count": null,
      "outputs": []
    }
  ]
}